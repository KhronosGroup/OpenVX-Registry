<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<!--[if IE]><meta http-equiv="X-UA-Compatible" content="IE=edge"><![endif]-->
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Asciidoctor 1.5.8">
<meta name="author" content="The Khronos® OpenVX Working Group, Editors: Radhakrishna Giduthuri, Tomer Schwartz, Mostafa Hagog">
<title>The OpenVX&#8482; Neural Network Extension</title>
<style>
/*! normalize.css v2.1.2 | MIT License | git.io/normalize */
/* ========================================================================== HTML5 display definitions ========================================================================== */
/** Correct `block` display not defined in IE 8/9. */
article, aside, details, figcaption, figure, footer, header, hgroup, main, nav, section, summary { display: block; }

/** Correct `inline-block` display not defined in IE 8/9. */
audio, canvas, video { display: inline-block; }

/** Prevent modern browsers from displaying `audio` without controls. Remove excess height in iOS 5 devices. */
audio:not([controls]) { display: none; height: 0; }

/** Address `[hidden]` styling not present in IE 8/9. Hide the `template` element in IE, Safari, and Firefox < 22. */
[hidden], template { display: none; }

script { display: none !important; }

/* ========================================================================== Base ========================================================================== */
/** 1. Set default font family to sans-serif. 2. Prevent iOS text size adjust after orientation change, without disabling user zoom. */
html { font-family: sans-serif; /* 1 */ -ms-text-size-adjust: 100%; /* 2 */ -webkit-text-size-adjust: 100%; /* 2 */ }

/** Remove default margin. */
body { margin: 0; }

/* ========================================================================== Links ========================================================================== */
/** Remove the gray background color from active links in IE 10. */
a { background: transparent; }

/** Address `outline` inconsistency between Chrome and other browsers. */
a:focus { outline: thin dotted; }

/** Improve readability when focused and also mouse hovered in all browsers. */
a:active, a:hover { outline: 0; }

/* ========================================================================== Typography ========================================================================== */
/** Address variable `h1` font-size and margin within `section` and `article` contexts in Firefox 4+, Safari 5, and Chrome. */
h1 { font-size: 1.9047619047619047em; margin: 0.67em 0; }

/** Address styling not present in IE 8/9, Safari 5, and Chrome. */
abbr[title] { border-bottom: 1px dotted; }

/** Address style set to `bolder` in Firefox 4+, Safari 5, and Chrome. */
b, strong { font-weight: bold; }

/** Address styling not present in Safari 5 and Chrome. */
dfn { font-style: italic; }

/** Address differences between Firefox and other browsers. */
hr { -moz-box-sizing: content-box; box-sizing: content-box; height: 0; }

/** Address styling not present in IE 8/9. */
mark { background: #ff0; color: #000; }

/** Correct font family set oddly in Safari 5 and Chrome. */
code, kbd, pre, samp { font-family: monospace, serif; font-size: 0.9523809523809523em; }

/** Improve readability of pre-formatted text in all browsers. */
pre { white-space: pre-wrap; }

/** Set consistent quote types. */
q { quotes: "\201C" "\201D" "\2018" "\2019"; }

/** Address inconsistent and variable font size in all browsers. */
small { font-size: 80%; }

/** Prevent `sub` and `sup` affecting `line-height` in all browsers. */
sub, sup { font-size: 75%; line-height: 0; position: relative; vertical-align: baseline; }

sup { top: -0.5em; }

sub { bottom: -0.25em; }

/* ========================================================================== Embedded content ========================================================================== */
/** Remove border when inside `a` element in IE 8/9. */
img { border: 0; }

/** Correct overflow displayed oddly in IE 9. */
svg:not(:root) { overflow: hidden; }

/* ========================================================================== Figures ========================================================================== */
/** Address margin not present in IE 8/9 and Safari 5. */
figure { margin: 0; }

/* ========================================================================== Forms ========================================================================== */
/** Define consistent border, margin, and padding. */
fieldset { border: 1px solid #c0c0c0; margin: 0 2px; padding: 0.35em 0.625em 0.75em; }

/** 1. Correct `color` not being inherited in IE 8/9. 2. Remove padding so people aren't caught out if they zero out fieldsets. */
legend { border: 0; /* 1 */ padding: 0; /* 2 */ }

/** 1. Correct font family not being inherited in all browsers. 2. Correct font size not being inherited in all browsers. 3. Address margins set differently in Firefox 4+, Safari 5, and Chrome. */
button, input, select, textarea { font-family: inherit; /* 1 */ font-size: 100%; /* 2 */ margin: 0; /* 3 */ }

/** Address Firefox 4+ setting `line-height` on `input` using `!important` in the UA stylesheet. */
button, input { line-height: normal; }

/** Address inconsistent `text-transform` inheritance for `button` and `select`. All other form control elements do not inherit `text-transform` values. Correct `button` style inheritance in Chrome, Safari 5+, and IE 8+. Correct `select` style inheritance in Firefox 4+ and Opera. */
button, select { text-transform: none; }

/** 1. Avoid the WebKit bug in Android 4.0.* where (2) destroys native `audio` and `video` controls. 2. Correct inability to style clickable `input` types in iOS. 3. Improve usability and consistency of cursor style between image-type `input` and others. */
button, html input[type="button"], input[type="reset"], input[type="submit"] { -webkit-appearance: button; /* 2 */ cursor: pointer; /* 3 */ }

/** Re-set default cursor for disabled elements. */
button[disabled], html input[disabled] { cursor: default; }

/** 1. Address box sizing set to `content-box` in IE 8/9. 2. Remove excess padding in IE 8/9. */
input[type="checkbox"], input[type="radio"] { box-sizing: border-box; /* 1 */ padding: 0; /* 2 */ }

/** 1. Address `appearance` set to `searchfield` in Safari 5 and Chrome. 2. Address `box-sizing` set to `border-box` in Safari 5 and Chrome (include `-moz` to future-proof). */
input[type="search"] { -webkit-appearance: textfield; /* 1 */ -moz-box-sizing: content-box; -webkit-box-sizing: content-box; /* 2 */ box-sizing: content-box; }

/** Remove inner padding and search cancel button in Safari 5 and Chrome on OS X. */
input[type="search"]::-webkit-search-cancel-button, input[type="search"]::-webkit-search-decoration { -webkit-appearance: none; }

/** Remove inner padding and border in Firefox 4+. */
button::-moz-focus-inner, input::-moz-focus-inner { border: 0; padding: 0; }

/** 1. Remove default vertical scrollbar in IE 8/9. 2. Improve readability and alignment in all browsers. */
textarea { overflow: auto; /* 1 */ vertical-align: top; /* 2 */ }

/* ========================================================================== Tables ========================================================================== */
/** Remove most spacing between table cells. */
table { border-collapse: collapse; border-spacing: 0; }

meta.foundation-mq-small { font-family: "only screen and (min-width: 768px)"; width: 768px; }

meta.foundation-mq-medium { font-family: "only screen and (min-width:1280px)"; width: 1280px; }

meta.foundation-mq-large { font-family: "only screen and (min-width:1440px)"; width: 1440px; }

*, *:before, *:after { -moz-box-sizing: border-box; -webkit-box-sizing: border-box; box-sizing: border-box; }

html, body { font-size: 100%; }

body { background: #fff; color: #222; padding: 0; margin: 0; font-family: "Helvetica Neue", "Helvetica", Helvetica, Arial, sans-serif; font-weight: normal; font-style: normal; line-height: 1; position: relative; cursor: auto; }

a:hover { cursor: pointer; }

img, object, embed { max-width: 100%; height: auto; }

object, embed { height: 100%; }

img { -ms-interpolation-mode: bicubic; }

#map_canvas img, #map_canvas embed, #map_canvas object, .map_canvas img, .map_canvas embed, .map_canvas object { max-width: none !important; }

.left { float: left !important; }

.right { float: right !important; }

.text-left { text-align: left !important; }

.text-right { text-align: right !important; }

.text-center { text-align: center !important; }

.text-justify { text-align: justify !important; }

.hide { display: none; }

.antialiased { -webkit-font-smoothing: antialiased; }

img { display: inline-block; vertical-align: middle; }

textarea { height: auto; min-height: 50px; }

select { width: 100%; }

object, svg { display: inline-block; vertical-align: middle; }

.center { margin-left: auto; margin-right: auto; }

.spread { width: 100%; }

p.lead, .paragraph.lead > p, #preamble > .sectionbody > .paragraph:first-of-type p { font-size: 1.1607142857142858em; line-height: 1.6; }

.subheader, .admonitionblock td.content > .title, .audioblock > .title, .exampleblock > .title, .imageblock > .title, .listingblock > .title, .literalblock > .title, .stemblock > .title, .openblock > .title, .paragraph > .title, .quoteblock > .title, table.tableblock > .title, .verseblock > .title, .videoblock > .title, .dlist > .title, .olist > .title, .ulist > .title, .qlist > .title, .hdlist > .title { line-height: 1.4; color: black; font-weight: 300; margin-top: 0.2em; margin-bottom: 0.5em; }

/* Typography resets */
div, dl, dt, dd, ul, ol, li, h1, h2, h3, #toctitle, .sidebarblock > .content > .title, h4, h5, h6, pre, form, p, blockquote, th, td { margin: 0; padding: 0; direction: ltr; }

/* Default Link Styles */
a { color: #0068b0; text-decoration: none; line-height: inherit; }
a:hover, a:focus { color: #333; }
a img { border: none; }

/* Default paragraph styles */
p { font-family: Noto, sans-serif; font-weight: normal; font-size: 0.9523809523809523em; line-height: 1.6; margin-bottom: 0.75em; text-rendering: optimizeLegibility; }
p aside { font-size: 0.8333333333333334em; line-height: 1.35; font-style: italic; }

/* Default header styles */
h1, h2, h3, #toctitle, .sidebarblock > .content > .title, h4, h5, h6 { font-family: Noto, sans-serif; font-weight: normal; font-style: normal; color: black; text-rendering: optimizeLegibility; margin-top: 0.5em; margin-bottom: 0.5em; line-height: 1.2125em; }
h1 small, h2 small, h3 small, #toctitle small, .sidebarblock > .content > .title small, h4 small, h5 small, h6 small { font-size: 60%; color: #4d4d4d; line-height: 0; }

h1 { font-size: 2.0238095238095237em; }

h2 { font-size: 1.6071428571428572em; }

h3, #toctitle, .sidebarblock > .content > .title { font-size: 1.3095238095238095em; }

h4 { font-size: 1.0714285714285714em; }

h5 { font-size: 1.0714285714285714em; }

h6 { font-size: 0.9523809523809523em; }

hr { border: solid #ddd; border-width: 1px 0 0; clear: both; margin: 1.25em 0 1.1875em; height: 0; }

/* Helpful Typography Defaults */
em, i { font-style: italic; line-height: inherit; }

strong, b { font-weight: bold; line-height: inherit; }

small { font-size: 60%; line-height: inherit; }

code { font-family: Consolas, "Liberation Mono", Courier, monospace; font-weight: normal; color: #264357; }

/* Lists */
ul, ol, dl { font-size: 0.9523809523809523em; line-height: 1.6; margin-bottom: 0.75em; list-style-position: outside; font-family: Noto, sans-serif; }

ul, ol { margin-left: 1.5em; }
ul.no-bullet, ol.no-bullet { margin-left: 1.5em; }

/* Unordered Lists */
ul li ul, ul li ol { margin-left: 1.25em; margin-bottom: 0; font-size: 0.9523809523809523em; /* Override nested font-size change */ }
ul.square li ul, ul.circle li ul, ul.disc li ul { list-style: inherit; }
ul.square { list-style-type: square; }
ul.circle { list-style-type: circle; }
ul.disc { list-style-type: disc; }
ul.no-bullet { list-style: none; }

/* Ordered Lists */
ol li ul, ol li ol { margin-left: 1.25em; margin-bottom: 0; }

/* Definition Lists */
dl dt { margin-bottom: 0.3em; font-weight: bold; }
dl dd { margin-bottom: 0.75em; }

/* Abbreviations */
abbr, acronym { text-transform: uppercase; font-size: 90%; color: black; border-bottom: 1px dotted #ddd; cursor: help; }

abbr { text-transform: none; }

/* Blockquotes */
blockquote { margin: 0 0 0.75em; padding: 0.5625em 1.25em 0 1.1875em; border-left: 1px solid #ddd; }
blockquote cite { display: block; font-size: 0.7738095238095238em; color: #5e93b8; }
blockquote cite:before { content: "\2014 \0020"; }
blockquote cite a, blockquote cite a:visited { color: #5e93b8; }

blockquote, blockquote p { line-height: 1.6; color: #333; }

/* Microformats */
.vcard { display: inline-block; margin: 0 0 1.25em 0; border: 1px solid #ddd; padding: 0.625em 0.75em; }
.vcard li { margin: 0; display: block; }
.vcard .fn { font-weight: bold; font-size: 0.8928571428571429em; }

.vevent .summary { font-weight: bold; }
.vevent abbr { cursor: auto; text-decoration: none; font-weight: bold; border: none; padding: 0 0.0625em; }

@media only screen and (min-width: 768px) { h1, h2, h3, #toctitle, .sidebarblock > .content > .title, h4, h5, h6 { line-height: 1.4; }
  h1 { font-size: 2.619047619047619em; }
  h2 { font-size: 2.2023809523809526em; }
  h3, #toctitle, .sidebarblock > .content > .title { font-size: 1.6071428571428572em; }
  h4 { font-size: 1.369047619047619em; } }
/* Tables */
table { background: #fff; margin-bottom: 1.25em; border: solid 1px #d8d8ce; }
table thead, table tfoot { background: #eee; font-weight: bold; }
table thead tr th, table thead tr td, table tfoot tr th, table tfoot tr td { padding: 0.5em 0.625em 0.625em; font-size: inherit; color: #222; text-align: left; }
table tr th, table tr td { padding: 0.5625em 0.625em; font-size: inherit; color: #6d6e71; }
table tr.even, table tr.alt, table tr:nth-of-type(even) { background: #f8f8f8; }
table thead tr th, table tfoot tr th, table tbody tr td, table tr td, table tfoot tr td { display: table-cell; line-height: 1.4; }

body { -moz-osx-font-smoothing: grayscale; -webkit-font-smoothing: antialiased; tab-size: 4; }

h1, h2, h3, #toctitle, .sidebarblock > .content > .title, h4, h5, h6 { line-height: 1.4; }

a:hover, a:focus { text-decoration: underline; }

.clearfix:before, .clearfix:after, .float-group:before, .float-group:after { content: " "; display: table; }
.clearfix:after, .float-group:after { clear: both; }

*:not(pre) > code { font-size: inherit; font-style: normal !important; letter-spacing: 0; padding: 0; background-color: transparent; -webkit-border-radius: 0; border-radius: 0; line-height: inherit; word-wrap: break-word; }
*:not(pre) > code.nobreak { word-wrap: normal; }
*:not(pre) > code.nowrap { white-space: nowrap; }

pre, pre > code { line-height: 1.6; color: #264357; font-family: Consolas, "Liberation Mono", Courier, monospace; font-weight: normal; }

em em { font-style: normal; }

strong strong { font-weight: normal; }

.keyseq { color: #333333; }

kbd { font-family: Consolas, "Liberation Mono", Courier, monospace; display: inline-block; color: black; font-size: 0.6190476190476191em; line-height: 1.45; background-color: #f7f7f7; border: 1px solid #ccc; -webkit-border-radius: 3px; border-radius: 3px; -moz-box-shadow: 0 1px 0 rgba(0, 0, 0, 0.2), 0 0 0 0.1em white inset; -webkit-box-shadow: 0 1px 0 rgba(0, 0, 0, 0.2), 0 0 0 0.1em white inset; box-shadow: 0 1px 0 rgba(0, 0, 0, 0.2), 0 0 0 0.1em white inset; margin: 0 0.15em; padding: 0.2em 0.5em; vertical-align: middle; position: relative; top: -0.1em; white-space: nowrap; }

.keyseq kbd:first-child { margin-left: 0; }

.keyseq kbd:last-child { margin-right: 0; }

.menuseq, .menuref { color: #000; }

.menuseq b:not(.caret), .menuref { font-weight: inherit; }

.menuseq { word-spacing: -0.02em; }
.menuseq b.caret { font-size: 1.1904761904761905em; line-height: 0.8; }
.menuseq i.caret { font-weight: bold; text-align: center; width: 0.45em; }

b.button:before, b.button:after { position: relative; top: -1px; font-weight: normal; }

b.button:before { content: "["; padding: 0 3px 0 2px; }

b.button:after { content: "]"; padding: 0 2px 0 3px; }

#header, #content, #footnotes, #footer { width: 100%; margin-left: auto; margin-right: auto; margin-top: 0; margin-bottom: 0; max-width: 62.5em; *zoom: 1; position: relative; padding-left: 1.5em; padding-right: 1.5em; }
#header:before, #header:after, #content:before, #content:after, #footnotes:before, #footnotes:after, #footer:before, #footer:after { content: " "; display: table; }
#header:after, #content:after, #footnotes:after, #footer:after { clear: both; }

#content { margin-top: 1.25em; }

#content:before { content: none; }

#header > h1:first-child { color: black; margin-top: 2.25rem; margin-bottom: 0; }
#header > h1:first-child + #toc { margin-top: 8px; border-top: 1px solid #ddd; }
#header > h1:only-child, body.toc2 #header > h1:nth-last-child(2) { border-bottom: 1px solid #ddd; padding-bottom: 8px; }
#header .details { border-bottom: 1px solid #ddd; line-height: 1.45; padding-top: 0.25em; padding-bottom: 0.25em; padding-left: 0.25em; color: #5e93b8; display: -ms-flexbox; display: -webkit-flex; display: flex; -ms-flex-flow: row wrap; -webkit-flex-flow: row wrap; flex-flow: row wrap; }
#header .details span:first-child { margin-left: -0.125em; }
#header .details span.email a { color: #333; }
#header .details br { display: none; }
#header .details br + span:before { content: "\00a0\2013\00a0"; }
#header .details br + span.author:before { content: "\00a0\22c5\00a0"; color: #333; }
#header .details br + span#revremark:before { content: "\00a0|\00a0"; }
#header #revnumber { text-transform: capitalize; }
#header #revnumber:after { content: "\00a0"; }

#content > h1:first-child:not([class]) { color: black; border-bottom: 1px solid #ddd; padding-bottom: 8px; margin-top: 0; padding-top: 1rem; margin-bottom: 1.25rem; }

#toc { border-bottom: 0 solid #ddd; padding-bottom: 0.5em; }
#toc > ul { margin-left: 0.125em; }
#toc ul.sectlevel0 > li > a { font-style: italic; }
#toc ul.sectlevel0 ul.sectlevel1 { margin: 0.5em 0; }
#toc ul { font-family: Noto, sans-serif; list-style-type: none; }
#toc li { line-height: 1.3334; margin-top: 0.3334em; }
#toc a { text-decoration: none; }
#toc a:active { text-decoration: underline; }

#toctitle { color: black; font-size: 1.1428571428571428em; }

@media only screen and (min-width: 768px) { #toctitle { font-size: 1.3095238095238095em; }
  body.toc2 { padding-left: 15em; padding-right: 0; }
  #toc.toc2 { margin-top: 0 !important; background-color: #fff; position: fixed; width: 15em; left: 0; top: 0; border-right: 1px solid #ddd; border-top-width: 0 !important; border-bottom-width: 0 !important; z-index: 1000; padding: 1.25em 1em; height: 100%; overflow: auto; }
  #toc.toc2 #toctitle { margin-top: 0; margin-bottom: 0.8rem; font-size: 1.1428571428571428em; }
  #toc.toc2 > ul { font-size: 0.8571428571428571em; margin-bottom: 0; }
  #toc.toc2 ul ul { margin-left: 0; padding-left: 1em; }
  #toc.toc2 ul.sectlevel0 ul.sectlevel1 { padding-left: 0; margin-top: 0.5em; margin-bottom: 0.5em; }
  body.toc2.toc-right { padding-left: 0; padding-right: 15em; }
  body.toc2.toc-right #toc.toc2 { border-right-width: 0; border-left: 1px solid #ddd; left: auto; right: 0; } }
@media only screen and (min-width: 1280px) { body.toc2 { padding-left: 20em; padding-right: 0; }
  #toc.toc2 { width: 20em; }
  #toc.toc2 #toctitle { font-size: 1.3095238095238095em; }
  #toc.toc2 > ul { font-size: 0.9047619047619048em; }
  #toc.toc2 ul ul { padding-left: 1.25em; }
  body.toc2.toc-right { padding-left: 0; padding-right: 20em; } }
#content #toc { border-style: solid; border-width: 1px; border-color: #e6e6e6; margin-bottom: 1.25em; padding: 1.25em; background: #fff; -webkit-border-radius: 0; border-radius: 0; }
#content #toc > :first-child { margin-top: 0; }
#content #toc > :last-child { margin-bottom: 0; }

#footer { max-width: 100%; background-color: none; padding: 1.25em; }

#footer-text { color: black; line-height: 1.44; }

#content { margin-bottom: 0.625em; }

.sect1 { padding-bottom: 0.625em; }

@media only screen and (min-width: 768px) { #content { margin-bottom: 1.25em; }
  .sect1 { padding-bottom: 1.25em; } }
.sect1:last-child { padding-bottom: 0; }

.sect1 + .sect1 { border-top: 0 solid #ddd; }

#content h1 > a.anchor, h2 > a.anchor, h3 > a.anchor, #toctitle > a.anchor, .sidebarblock > .content > .title > a.anchor, h4 > a.anchor, h5 > a.anchor, h6 > a.anchor { position: absolute; z-index: 1001; width: 1.5ex; margin-left: -1.5ex; display: block; text-decoration: none !important; visibility: hidden; text-align: center; font-weight: normal; }
#content h1 > a.anchor:before, h2 > a.anchor:before, h3 > a.anchor:before, #toctitle > a.anchor:before, .sidebarblock > .content > .title > a.anchor:before, h4 > a.anchor:before, h5 > a.anchor:before, h6 > a.anchor:before { content: "\00A7"; font-size: 0.8095238095238095em; display: block; padding-top: 0.1em; }
#content h1:hover > a.anchor, #content h1 > a.anchor:hover, h2:hover > a.anchor, h2 > a.anchor:hover, h3:hover > a.anchor, #toctitle:hover > a.anchor, .sidebarblock > .content > .title:hover > a.anchor, h3 > a.anchor:hover, #toctitle > a.anchor:hover, .sidebarblock > .content > .title > a.anchor:hover, h4:hover > a.anchor, h4 > a.anchor:hover, h5:hover > a.anchor, h5 > a.anchor:hover, h6:hover > a.anchor, h6 > a.anchor:hover { visibility: visible; }
#content h1 > a.link, h2 > a.link, h3 > a.link, #toctitle > a.link, .sidebarblock > .content > .title > a.link, h4 > a.link, h5 > a.link, h6 > a.link { color: black; text-decoration: none; }
#content h1 > a.link:hover, h2 > a.link:hover, h3 > a.link:hover, #toctitle > a.link:hover, .sidebarblock > .content > .title > a.link:hover, h4 > a.link:hover, h5 > a.link:hover, h6 > a.link:hover { color: black; }

.audioblock, .imageblock, .literalblock, .listingblock, .stemblock, .videoblock { margin-bottom: 1.25em; }

.admonitionblock td.content > .title, .audioblock > .title, .exampleblock > .title, .imageblock > .title, .listingblock > .title, .literalblock > .title, .stemblock > .title, .openblock > .title, .paragraph > .title, .quoteblock > .title, table.tableblock > .title, .verseblock > .title, .videoblock > .title, .dlist > .title, .olist > .title, .ulist > .title, .qlist > .title, .hdlist > .title { text-rendering: optimizeLegibility; text-align: left; }

table.tableblock > caption.title { white-space: nowrap; overflow: visible; max-width: 0; }

.paragraph.lead > p, #preamble > .sectionbody > .paragraph:first-of-type p { color: black; }

table.tableblock #preamble > .sectionbody > .paragraph:first-of-type p { font-size: inherit; }

.admonitionblock > table { border-collapse: separate; border: 0; background: none; width: 100%; }
.admonitionblock > table td.icon { text-align: center; width: 80px; }
.admonitionblock > table td.icon img { max-width: initial; }
.admonitionblock > table td.icon .title { font-weight: bold; font-family: Noto, sans-serif; text-transform: uppercase; }
.admonitionblock > table td.content { padding-left: 1.125em; padding-right: 1.25em; border-left: 1px solid #ddd; color: #5e93b8; }
.admonitionblock > table td.content > :last-child > :last-child { margin-bottom: 0; }

.exampleblock > .content { border-style: solid; border-width: 1px; border-color: #e6e6e6; margin-bottom: 1.25em; padding: 1.25em; background: #fff; -webkit-border-radius: 0; border-radius: 0; }
.exampleblock > .content > :first-child { margin-top: 0; }
.exampleblock > .content > :last-child { margin-bottom: 0; }

.sidebarblock { border-style: solid; border-width: 1px; border-color: #e6e6e6; margin-bottom: 1.25em; padding: 1.25em; background: #fff; -webkit-border-radius: 0; border-radius: 0; }
.sidebarblock > :first-child { margin-top: 0; }
.sidebarblock > :last-child { margin-bottom: 0; }
.sidebarblock > .content > .title { color: black; margin-top: 0; }

.exampleblock > .content > :last-child > :last-child, .exampleblock > .content .olist > ol > li:last-child > :last-child, .exampleblock > .content .ulist > ul > li:last-child > :last-child, .exampleblock > .content .qlist > ol > li:last-child > :last-child, .sidebarblock > .content > :last-child > :last-child, .sidebarblock > .content .olist > ol > li:last-child > :last-child, .sidebarblock > .content .ulist > ul > li:last-child > :last-child, .sidebarblock > .content .qlist > ol > li:last-child > :last-child { margin-bottom: 0; }

.literalblock pre, .listingblock pre:not(.highlight), .listingblock pre[class="highlight"], .listingblock pre[class^="highlight "], .listingblock pre.CodeRay, .listingblock pre.prettyprint { background: #eee; }
.sidebarblock .literalblock pre, .sidebarblock .listingblock pre:not(.highlight), .sidebarblock .listingblock pre[class="highlight"], .sidebarblock .listingblock pre[class^="highlight "], .sidebarblock .listingblock pre.CodeRay, .sidebarblock .listingblock pre.prettyprint { background: #f2f1f1; }

.literalblock pre, .literalblock pre[class], .listingblock pre, .listingblock pre[class] { border: 1px hidden #666; -webkit-border-radius: 0; border-radius: 0; word-wrap: break-word; padding: 1.25em 1.5625em 1.125em 1.5625em; font-size: 0.7738095238095238em; }
.literalblock pre.nowrap, .literalblock pre[class].nowrap, .listingblock pre.nowrap, .listingblock pre[class].nowrap { overflow-x: auto; white-space: pre; word-wrap: normal; }
@media only screen and (min-width: 768px) { .literalblock pre, .literalblock pre[class], .listingblock pre, .listingblock pre[class] { font-size: 0.8630952380952381em; } }
@media only screen and (min-width: 1280px) { .literalblock pre, .literalblock pre[class], .listingblock pre, .listingblock pre[class] { font-size: 0.9523809523809523em; } }

.literalblock.output pre { color: #eee; background-color: #264357; }

.listingblock pre.highlightjs { padding: 0; }
.listingblock pre.highlightjs > code { padding: 1.25em 1.5625em 1.125em 1.5625em; -webkit-border-radius: 0; border-radius: 0; }

.listingblock > .content { position: relative; }

.listingblock code[data-lang]:before { display: none; content: attr(data-lang); position: absolute; font-size: 0.7142857142857143em; top: 0.425rem; right: 0.5rem; line-height: 1; text-transform: uppercase; color: #999; }

.listingblock:hover code[data-lang]:before { display: block; }

.listingblock.terminal pre .command:before { content: attr(data-prompt); padding-right: 0.5em; color: #999; }

.listingblock.terminal pre .command:not([data-prompt]):before { content: "$"; }

table.pyhltable { border-collapse: separate; border: 0; margin-bottom: 0; background: none; }

table.pyhltable td { vertical-align: top; padding-top: 0; padding-bottom: 0; line-height: 1.6; }

table.pyhltable td.code { padding-left: .75em; padding-right: 0; }

pre.pygments .lineno, table.pyhltable td:not(.code) { color: #999; padding-left: 0; padding-right: .5em; border-right: 1px solid #ddd; }

pre.pygments .lineno { display: inline-block; margin-right: .25em; }

table.pyhltable .linenodiv { background: none !important; padding-right: 0 !important; }

.quoteblock { margin: 0 1em 0.75em 1.5em; display: table; }
.quoteblock > .title { margin-left: -1.5em; margin-bottom: 0.75em; }
.quoteblock blockquote, .quoteblock blockquote p { color: #333; font-size: 1.15rem; line-height: 1.75; word-spacing: 0.1em; letter-spacing: 0; font-style: italic; text-align: justify; }
.quoteblock blockquote { margin: 0; padding: 0; border: 0; }
.quoteblock blockquote:before { content: "\201c"; float: left; font-size: 2.619047619047619em; font-weight: bold; line-height: 0.6em; margin-left: -0.6em; color: black; text-shadow: 0 1px 2px rgba(0, 0, 0, 0.1); }
.quoteblock blockquote > .paragraph:last-child p { margin-bottom: 0; }
.quoteblock .attribution { margin-top: 0.5em; margin-right: 0.5ex; text-align: right; }
.quoteblock .quoteblock { margin-left: 0; margin-right: 0; padding: 0.5em 0; border-left: 3px solid #5e93b8; }
.quoteblock .quoteblock blockquote { padding: 0 0 0 0.75em; }
.quoteblock .quoteblock blockquote:before { display: none; }

.verseblock { margin: 0 1em 0.75em 1em; }
.verseblock pre { font-family: "Open Sans", "DejaVu Sans", sans; font-size: 1.15rem; color: #333; font-weight: 300; text-rendering: optimizeLegibility; }
.verseblock pre strong { font-weight: 400; }
.verseblock .attribution { margin-top: 1.25rem; margin-left: 0.5ex; }

.quoteblock .attribution, .verseblock .attribution { font-size: 0.7738095238095238em; line-height: 1.45; font-style: italic; }
.quoteblock .attribution br, .verseblock .attribution br { display: none; }
.quoteblock .attribution cite, .verseblock .attribution cite { display: block; letter-spacing: -0.025em; color: #5e93b8; }

.quoteblock.abstract { margin: 0 0 0.75em 0; display: block; }
.quoteblock.abstract blockquote, .quoteblock.abstract blockquote p { text-align: left; word-spacing: 0; }
.quoteblock.abstract blockquote:before, .quoteblock.abstract blockquote p:first-of-type:before { display: none; }

table.tableblock { max-width: 100%; border-collapse: separate; }
table.tableblock td > .paragraph:last-child p > p:last-child, table.tableblock th > p:last-child, table.tableblock td > p:last-child { margin-bottom: 0; }

table.tableblock, th.tableblock, td.tableblock { border: 0 solid #d8d8ce; }

table.grid-all > thead > tr > .tableblock, table.grid-all > tbody > tr > .tableblock { border-width: 0 1px 1px 0; }

table.grid-all > tfoot > tr > .tableblock { border-width: 1px 1px 0 0; }

table.grid-cols > * > tr > .tableblock { border-width: 0 1px 0 0; }

table.grid-rows > thead > tr > .tableblock, table.grid-rows > tbody > tr > .tableblock { border-width: 0 0 1px 0; }

table.grid-rows > tfoot > tr > .tableblock { border-width: 1px 0 0 0; }

table.grid-all > * > tr > .tableblock:last-child, table.grid-cols > * > tr > .tableblock:last-child { border-right-width: 0; }

table.grid-all > tbody > tr:last-child > .tableblock, table.grid-all > thead:last-child > tr > .tableblock, table.grid-rows > tbody > tr:last-child > .tableblock, table.grid-rows > thead:last-child > tr > .tableblock { border-bottom-width: 0; }

table.frame-all { border-width: 1px; }

table.frame-sides { border-width: 0 1px; }

table.frame-topbot { border-width: 1px 0; }

th.halign-left, td.halign-left { text-align: left; }

th.halign-right, td.halign-right { text-align: right; }

th.halign-center, td.halign-center { text-align: center; }

th.valign-top, td.valign-top { vertical-align: top; }

th.valign-bottom, td.valign-bottom { vertical-align: bottom; }

th.valign-middle, td.valign-middle { vertical-align: middle; }

table thead th, table tfoot th { font-weight: bold; }

tbody tr th { display: table-cell; line-height: 1.4; background: #eee; }

tbody tr th, tbody tr th p, tfoot tr th, tfoot tr th p { color: #222; font-weight: bold; }

p.tableblock > code:only-child { background: none; padding: 0; }

p.tableblock { font-size: 0.9523809523809523em; }

td > div.verse { white-space: pre; }

ol { margin-left: 1.75em; }

ul li ol { margin-left: 1.5em; }

dl dd { margin-left: 1.125em; }

dl dd:last-child, dl dd:last-child > :last-child { margin-bottom: 0; }

ol > li p, ul > li p, ul dd, ol dd, .olist .olist, .ulist .ulist, .ulist .olist, .olist .ulist { margin-bottom: 0.375em; }

ul.checklist, ul.none, ol.none, ul.no-bullet, ol.no-bullet, ol.unnumbered, ul.unstyled, ol.unstyled { list-style-type: none; }

ul.no-bullet, ol.no-bullet, ol.unnumbered { margin-left: 0.625em; }

ul.unstyled, ol.unstyled { margin-left: 0; }

ul.checklist { margin-left: 0.625em; }

ul.checklist li > p:first-child > .fa-square-o:first-child, ul.checklist li > p:first-child > .fa-check-square-o:first-child { width: 1.25em; font-size: 0.7619047619047619em; position: relative; bottom: 0.125em; }

ul.checklist li > p:first-child > input[type="checkbox"]:first-child { margin-right: 0.25em; }

ul.inline { display: -ms-flexbox; display: -webkit-box; display: flex; -ms-flex-flow: row wrap; -webkit-flex-flow: row wrap; flex-flow: row wrap; list-style: none; margin: 0 0 0.375em -0.75em; }

ul.inline > li { margin-left: 0.75em; }

.unstyled dl dt { font-weight: normal; font-style: normal; }

ol.arabic { list-style-type: decimal; }

ol.decimal { list-style-type: decimal-leading-zero; }

ol.loweralpha { list-style-type: lower-alpha; }

ol.upperalpha { list-style-type: upper-alpha; }

ol.lowerroman { list-style-type: lower-roman; }

ol.upperroman { list-style-type: upper-roman; }

ol.lowergreek { list-style-type: lower-greek; }

.hdlist > table, .colist > table { border: 0; background: none; }
.hdlist > table > tbody > tr, .colist > table > tbody > tr { background: none; }

td.hdlist1, td.hdlist2 { vertical-align: top; padding: 0 0.625em; }

td.hdlist1 { font-weight: bold; padding-bottom: 0.75em; }

.literalblock + .colist, .listingblock + .colist { margin-top: -0.5em; }

.colist > table tr > td:first-of-type { padding: 0.4em 0.75em 0 0.75em; line-height: 1; vertical-align: top; }
.colist > table tr > td:first-of-type img { max-width: initial; }
.colist > table tr > td:last-of-type { padding: 0.25em 0; }

.thumb, .th { line-height: 0; display: inline-block; border: solid 4px #fff; -webkit-box-shadow: 0 0 0 1px #ddd; box-shadow: 0 0 0 1px #ddd; }

.imageblock.left, .imageblock[style*="float: left"] { margin: 0.25em 0.625em 1.25em 0; }
.imageblock.right, .imageblock[style*="float: right"] { margin: 0.25em 0 1.25em 0.625em; }
.imageblock > .title { margin-bottom: 0; }
.imageblock.thumb, .imageblock.th { border-width: 6px; }
.imageblock.thumb > .title, .imageblock.th > .title { padding: 0 0.125em; }

.image.left, .image.right { margin-top: 0.25em; margin-bottom: 0.25em; display: inline-block; line-height: 0; }
.image.left { margin-right: 0.625em; }
.image.right { margin-left: 0.625em; }

a.image { text-decoration: none; display: inline-block; }
a.image object { pointer-events: none; }

sup.footnote, sup.footnoteref { font-size: 0.8333333333333334em; position: static; vertical-align: super; }
sup.footnote a, sup.footnoteref a { text-decoration: none; }
sup.footnote a:active, sup.footnoteref a:active { text-decoration: underline; }

#footnotes { padding-top: 0.75em; padding-bottom: 0.75em; margin-bottom: 0.625em; }
#footnotes hr { width: 20%; min-width: 6.25em; margin: -0.25em 0 0.75em 0; border-width: 1px 0 0 0; }
#footnotes .footnote { padding: 0 0.375em 0 0.225em; line-height: 1.3334; font-size: 0.8333333333333334em; margin-left: 1.2em; margin-bottom: 0.2em; }
#footnotes .footnote a:first-of-type { font-weight: bold; text-decoration: none; margin-left: -1.05em; }
#footnotes .footnote:last-of-type { margin-bottom: 0; }
#content #footnotes { margin-top: -0.625em; margin-bottom: 0; padding: 0.75em 0; }

.gist .file-data > table { border: 0; background: #fff; width: 100%; margin-bottom: 0; }
.gist .file-data > table td.line-data { width: 99%; }

div.unbreakable { page-break-inside: avoid; }

.big { font-size: larger; }

.small { font-size: smaller; }

.underline { text-decoration: underline; }

.overline { text-decoration: overline; }

.line-through { text-decoration: line-through; }

.aqua { color: #00bfbf; }

.aqua-background { background-color: #00fafa; }

.black { color: black; }

.black-background { background-color: black; }

.blue { color: #0000bf; }

.blue-background { background-color: #0000fa; }

.fuchsia { color: #bf00bf; }

.fuchsia-background { background-color: #fa00fa; }

.gray { color: #606060; }

.gray-background { background-color: #7d7d7d; }

.green { color: #006000; }

.green-background { background-color: #007d00; }

.lime { color: #00bf00; }

.lime-background { background-color: #00fa00; }

.maroon { color: #600000; }

.maroon-background { background-color: #7d0000; }

.navy { color: #000060; }

.navy-background { background-color: #00007d; }

.olive { color: #606000; }

.olive-background { background-color: #7d7d00; }

.purple { color: #600060; }

.purple-background { background-color: #7d007d; }

.red { color: #bf0000; }

.red-background { background-color: #fa0000; }

.silver { color: #909090; }

.silver-background { background-color: #bcbcbc; }

.teal { color: #006060; }

.teal-background { background-color: #007d7d; }

.white { color: #bfbfbf; }

.white-background { background-color: #fafafa; }

.yellow { color: #bfbf00; }

.yellow-background { background-color: #fafa00; }

span.icon > .fa { cursor: default; }
a span.icon > .fa { cursor: inherit; }

.admonitionblock td.icon [class^="fa icon-"] { font-size: 2.380952380952381em; text-shadow: 1px 1px 2px rgba(0, 0, 0, 0.5); cursor: default; }
.admonitionblock td.icon .icon-note:before { content: "\f05a"; color: #29475c; }
.admonitionblock td.icon .icon-tip:before { content: "\f0eb"; text-shadow: 1px 1px 2px rgba(155, 155, 0, 0.8); color: #111; }
.admonitionblock td.icon .icon-warning:before { content: "\f071"; color: #bf6900; }
.admonitionblock td.icon .icon-caution:before { content: "\f06d"; color: #bf3400; }
.admonitionblock td.icon .icon-important:before { content: "\f06a"; color: #bf0000; }

.conum[data-value] { display: inline-block; color: #fff !important; background-color: black; -webkit-border-radius: 100px; border-radius: 100px; text-align: center; font-size: 0.7142857142857143em; width: 1.67em; height: 1.67em; line-height: 1.67em; font-family: "Open Sans", "DejaVu Sans", sans-serif; font-style: normal; font-weight: bold; }
.conum[data-value] * { color: #fff !important; }
.conum[data-value] + b { display: none; }
.conum[data-value]:after { content: attr(data-value); }
pre .conum[data-value] { position: relative; top: -0.125em; }

b.conum * { color: inherit !important; }

.conum:not([data-value]):empty { display: none; }

h1, h2, h3, #toctitle, .sidebarblock > .content > .title, h4, h5, h6 { border-bottom: 1px solid #ddd; }

.sect1 { padding-bottom: 0; }

#toctitle { color: #00406F; font-weight: normal; margin-top: 1.5em; }

.sidebarblock { border-color: #aaa; }

code { -webkit-border-radius: 4px; border-radius: 4px; }

p.tableblock.header { color: #6d6e71; }

.literalblock pre, .listingblock pre { background: #eee; }

</style>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
<style>
/* Stylesheet for CodeRay to match GitHub theme | MIT License | http://foundation.zurb.com */
/*pre.CodeRay {background-color:#f7f7f8;}*/
.CodeRay .line-numbers{border-right:1px solid #d8d8d8;padding:0 0.5em 0 .25em}
.CodeRay span.line-numbers{display:inline-block;margin-right:.5em;color:rgba(0,0,0,.3)}
.CodeRay .line-numbers strong{color:rgba(0,0,0,.4)}
table.CodeRay{border-collapse:separate;border-spacing:0;margin-bottom:0;border:0;background:none}
table.CodeRay td{vertical-align: top;line-height:1.45}
table.CodeRay td.line-numbers{text-align:right}
table.CodeRay td.line-numbers>pre{padding:0;color:rgba(0,0,0,.3)}
table.CodeRay td.code{padding:0 0 0 .5em}
table.CodeRay td.code>pre{padding:0}
.CodeRay .debug{color:#fff !important;background:#000080 !important}
.CodeRay .annotation{color:#007}
.CodeRay .attribute-name{color:#000080}
.CodeRay .attribute-value{color:#700}
.CodeRay .binary{color:#509}
.CodeRay .comment{color:#998;font-style:italic}
.CodeRay .char{color:#04d}
.CodeRay .char .content{color:#04d}
.CodeRay .char .delimiter{color:#039}
.CodeRay .class{color:#458;font-weight:bold}
.CodeRay .complex{color:#a08}
.CodeRay .constant,.CodeRay .predefined-constant{color:#008080}
.CodeRay .color{color:#099}
.CodeRay .class-variable{color:#369}
.CodeRay .decorator{color:#b0b}
.CodeRay .definition{color:#099}
.CodeRay .delimiter{color:#000}
.CodeRay .doc{color:#970}
.CodeRay .doctype{color:#34b}
.CodeRay .doc-string{color:#d42}
.CodeRay .escape{color:#666}
.CodeRay .entity{color:#800}
.CodeRay .error{color:#808}
.CodeRay .exception{color:inherit}
.CodeRay .filename{color:#099}
.CodeRay .function{color:#900;font-weight:bold}
.CodeRay .global-variable{color:#008080}
.CodeRay .hex{color:#058}
.CodeRay .integer,.CodeRay .float{color:#099}
.CodeRay .include{color:#555}
.CodeRay .inline{color:#000}
.CodeRay .inline .inline{background:#ccc}
.CodeRay .inline .inline .inline{background:#bbb}
.CodeRay .inline .inline-delimiter{color:#d14}
.CodeRay .inline-delimiter{color:#d14}
.CodeRay .important{color:#555;font-weight:bold}
.CodeRay .interpreted{color:#b2b}
.CodeRay .instance-variable{color:#008080}
.CodeRay .label{color:#970}
.CodeRay .local-variable{color:#963}
.CodeRay .octal{color:#40e}
.CodeRay .predefined{color:#369}
.CodeRay .preprocessor{color:#579}
.CodeRay .pseudo-class{color:#555}
.CodeRay .directive{font-weight:bold}
.CodeRay .type{font-weight:bold}
.CodeRay .predefined-type{color:inherit}
.CodeRay .reserved,.CodeRay .keyword {color:#000;font-weight:bold}
.CodeRay .key{color:#808}
.CodeRay .key .delimiter{color:#606}
.CodeRay .key .char{color:#80f}
.CodeRay .value{color:#088}
.CodeRay .regexp .delimiter{color:#808}
.CodeRay .regexp .content{color:#808}
.CodeRay .regexp .modifier{color:#808}
.CodeRay .regexp .char{color:#d14}
.CodeRay .regexp .function{color:#404;font-weight:bold}
.CodeRay .string{color:#d20}
.CodeRay .string .string .string{background:#ffd0d0}
.CodeRay .string .content{color:#d14}
.CodeRay .string .char{color:#d14}
.CodeRay .string .delimiter{color:#d14}
.CodeRay .shell{color:#d14}
.CodeRay .shell .delimiter{color:#d14}
.CodeRay .symbol{color:#990073}
.CodeRay .symbol .content{color:#a60}
.CodeRay .symbol .delimiter{color:#630}
.CodeRay .tag{color:#008080}
.CodeRay .tag-special{color:#d70}
.CodeRay .variable{color:#036}
.CodeRay .insert{background:#afa}
.CodeRay .delete{background:#faa}
.CodeRay .change{color:#aaf;background:#007}
.CodeRay .head{color:#f8f;background:#505}
.CodeRay .insert .insert{color:#080}
.CodeRay .delete .delete{color:#800}
.CodeRay .change .change{color:#66f}
.CodeRay .head .head{color:#f4f}
</style>
<link rel="stylesheet" href="katex/katex.min.css">
<script src="katex/katex.min.js"></script>
<script src="katex/contrib/auto-render.min.js"></script>
    <!-- Use KaTeX to render math once document is loaded, see
         https://github.com/Khan/KaTeX/tree/master/contrib/auto-render -->
<script>
    document.addEventListener("DOMContentLoaded", function () {
        renderMathInElement(
            document.body,
            {
                delimiters: [
                    { left: "$$", right: "$$", display: true},
                    { left: "\\[", right: "\\]", display: true},
                    { left: "$", right: "$", display: false},
                    { left: "\\(", right: "\\)", display: false}
                ]
            }
        );
    });
</script></head>
<body class="book toc2 toc-left" style="max-width: 100;">
<div id="header">
<h1>The OpenVX<sup>&#8482;</sup> Neural Network Extension</h1>
<div class="details">
<span id="author" class="author">The Khronos<sup>®</sup> OpenVX Working Group</span><br>
<span id="author2" class="author">Editors: Radhakrishna Giduthuri, Tomer Schwartz, Mostafa Hagog</span><br>
<span id="revnumber">version 1.3,</span>
<span id="revdate">Thu, 08 Aug 2019 20:28:08 +0000</span>
<br><span id="revremark">Git branch information not available</span>
</div>
<div id="toc" class="toc2">
<div id="toctitle">Table of Contents</div>
<ul class="sectlevel1">
<li><a href="#_neural_network_extension">1. Neural Network Extension</a>
<ul class="sectlevel2">
<li><a href="#sec_acknowledgements">1.1. Acknowledgements</a></li>
<li><a href="#sec_background">1.2. Background and Terminology</a></li>
<li><a href="#sec_cnn">1.3. Introduction</a></li>
<li><a href="#sec_weights">1.4. Weights/Biasses Setting</a></li>
<li><a href="#sec_kernel_names">1.5. Kernel names</a></li>
<li><a href="#sec_extensions">1.6. 8-bit extension and 16-bit extension</a></li>
</ul>
</li>
<li><a href="#module_documentation">2. Module Documentation</a>
<ul class="sectlevel2">
<li><a href="#group_cnn">2.1. Extension: Deep Convolutional Networks API</a>
<ul class="sectlevel3">
<li><a href="#_data_structures">2.1.1. Data Structures</a></li>
<li><a href="#_macros">2.1.2. Macros</a></li>
<li><a href="#_enumerations">2.1.3. Enumerations</a></li>
<li><a href="#_functions">2.1.4. Functions</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
<div id="content">
<div id="preamble">
<div class="sectionbody">
<div class="imageblock text-center">
<div class="content">
<img src="data:image/svg+xml;base64,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" alt="OpenVX RGB" width="400">
</div>
</div>
<div class="paragraph">
<p>Copyright 2013-2019 The Khronos Group Inc.</p>
</div>
<div class="paragraph">
<p>This specification is protected by copyright laws and contains material
proprietary to Khronos.
Except as described by these terms, it or any components may not be
reproduced, republished, distributed, transmitted, displayed, broadcast or
otherwise exploited in any manner without the express prior written
permission of Khronos.</p>
</div>
<div class="paragraph">
<p>This specification has been created under the Khronos Intellectual Property
Rights Policy, which is Attachment A of the Khronos Group Membership
Agreement available at www.khronos.org/files/member_agreement.pdf.
Khronos Group grants a conditional copyright license to use and reproduce
the unmodified specification for any purpose, without fee or royalty, EXCEPT
no licenses to any patent, trademark or other intellectual property rights
are granted under these terms.
Parties desiring to implement the specification and make use of Khronos
trademarks in relation to that implementation, and receive reciprocal patent
license protection under the Khronos IP Policy must become Adopters and
confirm the implementation as conformant under the process defined by
Khronos for this specification; see <a href="https://www.khronos.org/adopters" class="bare">https://www.khronos.org/adopters</a>.</p>
</div>
<div class="paragraph">
<p>Khronos makes no, and expressly disclaims any, representations or
warranties, express or implied, regarding this specification, including,
without limitation: merchantability, fitness for a particular purpose,
non-infringement of any intellectual property, correctness, accuracy,
completeness, timeliness, and reliability.
Under no circumstances will Khronos, or any of its Promoters, Contributors
or Members, or their respective partners, officers, directors, employees,
agents or representatives be liable for any damages, whether direct,
indirect, special or consequential damages for lost revenues, lost profits,
or otherwise, arising from or in connection with these materials.</p>
</div>
<div class="paragraph">
<p>Khronos is a registered trademark, and OpenVX is a trademark of The Khronos
Group Inc.
OpenCL is a trademark of Apple Inc., used under license by Khronos.
All other product names, trademarks, and/or company names are used solely
for identification and belong to their respective owners.</p>
</div>
<div style="page-break-after: always;"></div>
<!-- toc disabled -->
</div>
</div>
<div class="sect1">
<h2 id="_neural_network_extension">1. Neural Network Extension</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="sec_acknowledgements">1.1. Acknowledgements</h3>
<div class="paragraph">
<p>This specification would not be possible without the contributions from this
partial list of the following individuals from the Khronos Working Group and
the companies that they represented at the time:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Radhakrishna Giduthuri - Intel</p>
</li>
<li>
<p>Frank Brill - Cadence Design Systems</p>
</li>
<li>
<p>Thierry Lepley - Cadence Design Systems</p>
</li>
<li>
<p>Kari Pulli - Intel</p>
</li>
<li>
<p>Mostafa Hagog - Intel</p>
</li>
<li>
<p>Tomer Schwartz - Intel</p>
</li>
<li>
<p>Victor Eruhimov - Itseez3D</p>
</li>
<li>
<p>Chuck Pilkington - Synopsis</p>
</li>
<li>
<p>Jesse Villarreal - Texas Instruments</p>
</li>
<li>
<p>Xin Wang - Verisilicon</p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="sec_background">1.2. Background and Terminology</h3>
<div class="paragraph">
<p>Deep Learning using Neural Networks techniques is being increasingly used to
perform vision classification and recognition tasks.
Deep Neural Networks have significantly improved image recognition
capabilities over previous technologies.
The Neural Network extension for OpenVX is intended to enable the
implementation of Deep Neural Network in the OpenVX framework.
It is well known that the Deep learning domain for vision, has two
fundamental stages.
At first the network topology is designed and trained given a collection of
labelled data.
The network topology is represented as a graph of several nodes comprising
Neural Network building block.
The trained data represents the problem to be addressed.
During the training Phase, the parameters (also referred to as
weights/biasses or coefficients) are determined for the given network
topology.
The network topology solution can then be deployed.</p>
</div>
<div class="paragraph">
<p>In Deployment the network topology as well as parameters are fixed which
allow optimizing in hardware and software.
In certain scenarios an additional intermediate step is performed to
optimize the parameters to a certain target hardware.
As an example, using fixed point calculations.
When Deployed, the Neural Network is used for inferences on input data.
The main objective of the Neural Network Extension for OpenVX is to enable
the deployment phase (in other words inferences).</p>
</div>
<div class="paragraph">
<p>This section provides the definition of the basic terminology to be used
across the document, in an attempt to address the various use and different
naming in the academy as well as the industry.
Those names refer to the same fundamental concept of Deep Neural Networks in
the deep learning domain.
We refer to the term Deep Neural Network to the network topology of the deep
learning network, that is composed of multiple layers in which one of the
main layer is Convolution.
Other names used in the academia and industry to refer to the same type of
network topologies are CNN (Convolutional Neural Networks) and ConvNets.
Throughout this document we will use the Deep Neural Network to refer to the
Neural Network, CNN and ConvNet.</p>
</div>
<div class="paragraph">
<p>Weights - Will use the term Weights to refer to the parameters or
coefficients that are the result of training the Deep Neural Network.
Weights can be shared or non shared.
Or have local connectivity.</p>
</div>
<div class="paragraph">
<p>Biasses - Will use the term Biasses to refer to the parameters or
coefficients, per output only, that are the result of training the Deep
Neural Network.</p>
</div>
<div class="paragraph">
<p>Convolution Layer - A type of layer in the Deep Neural Network that has
local connectivity and shared weights, other naming are Locality connected
with shared weights.</p>
</div>
<div class="paragraph">
<p>Fully Connected Layer - All inputs to the layer affect outputs of the layer
, in other words connection from every element of input to every element of
output.</p>
</div>
<div class="paragraph">
<p>Activation Layer - A layer that performs operations on every input data and
is inspired by the neuron activation function approximated usually using
non-Linear functions.</p>
</div>
<div class="paragraph">
<p>The documentation below uses the abbreviations IFM and OFM, which stand for
&#8220;Input Feature Maps&#8221; and &#8220;Output Feature Maps,&#8221; respectively.
Each feature map is a 2 dimensional image.
A CNN input or output tensor will typically have 3 dimensions, where the
first two are the width and height of the images, and the third is the
number of feature maps.
For inputs, the third dimension is the number of IFMs, and for outputs, the
third dimension is the number of OFMs.</p>
</div>
</div>
<div class="sect2">
<h3 id="sec_cnn">1.3. Introduction</h3>
<div class="paragraph">
<p>The Neural Networks extension enables execution and integration of Deep
Neural Networks in OpenVX processing graphs.
The extension is dependent on a <code>vx_tensor</code> object which is introduced
in OpenVX 1.2.
Therefore this extension is extending OpenVX 1.2 and not previous OpenVX
specifications.
The <code>vx_tensor</code> object is a multidimensional array with an arbitrary
number of dimensions.
The <code>vx_tensor</code> object can represent all varieties of data typically
used in a Deep Neural Network.
It can represent 2-dimensional images, 3-dimensional sequences of images
(usually the input and outputs of a Deep Neural Network) and 4-dimensional
weights.</p>
</div>
<div class="paragraph">
<p>Application can build an OpenVX graph that represents Deep Neural Network
topologies where the layers are represented as OpenVX nodes (<code>vx_node</code>)
and the <code>vx_tensor</code> as the data objects connecting the nodes (layers) of
the OpenVX graph (Deep Neural Network).
The application can as well build an OpenVX graph that is a mix of Deep
Neural Network layers and Vision nodes.
All graphs (including Deep Neural Networks) are treated as any OpenVX graph,
and must comply with the graph concepts as specified in section 2.8 of
OpenVX 1.1, especially but not limit to the graph formalisms in section
2.8.6.
Additionally, this extension defines several auxiliary functions to create,
release, and copy <code>vx_tensor</code> objects.
Moreover, the extension introduces the concept of &#8220;view&#8221; for
<code>vx_tensor</code> objects, which is similar to the ROI of a <code>vx_image</code>.
The use of &#8220;view&#8221; enables splitting and merging <code>vx_tensor</code> objects,
which are common operations in Convolutional Networks.
The layers of the Deep Neural Network (represented by <code>vx_node</code> objects)
perform the computations on the tensor data objects and form a dataflow
graph of computations.
The extension defines the following layer types: convolution, activation,
pooling, fully-connected, and soft-max.</p>
</div>
</div>
<div class="sect2">
<h3 id="sec_weights">1.4. Weights/Biasses Setting</h3>
<div class="paragraph">
<p>It is assumed that the Deep Neural Networks are trained in framework
external to OpenVX and imported.
This requires the application to allocate a memory area for the
weights/biasses, read the weight values from a file into this memory area,
and then use the <code>vxCopyTensorPatch</code> API to copy the weights/biasses from
the memory area into the appropriate OpenVX Tensor object.
The <code>vxCopyTensorPatch</code> function will convert the application memory to the
implementation-specific format before putting it into the Tensor object.
While effective, this method has the drawback that an intermediate memory
area needs to be allocated and a copy and conversion needs to be done.</p>
</div>
<div class="paragraph">
<p>A separate &#8220;import/export&#8221; extension defines a <code>vxImportBinary</code> function
that can be implemented more efficiently.
Implementations of <code>vxImportBinary</code> could read a weight file or perhaps an
entire graph description directly without the need for an intermediate copy.
The format of this binary will be implementation-dependent.
OpenVX implementations that support both the Neural Network extension and
the binary import/export extension can use this more efficient method to set
the Deep Neural Networks weights/biasses.
The <code>vxImportBinary</code> function will return a handle to an object that can be
queried to get handles for the individual objects within it via the
<code>vxGetImportReferenceByName</code> or <code>vxGetImportReferenceByIndex</code> functions.
Further details and alternate usages of the <code>vxImportBinary</code> function are
provided in the specification of the &#8220;import/export&#8221; extension.</p>
</div>
<div class="paragraph">
<p>OpenVX objects (tensors, scalars, enums) for weights, biases and other
static parameters of CNN layers must have actual data loaded into them
before <code>vxVerifyGraph()</code> is called, therefore implementation may cache them
prior to execution or use them for other optimizations.
Optionally, implementation may explicitly define support to change weights
after <code>vxVerifyGraph()</code> was called or between <code>vxProcessGraph()</code> calls.
For convenience we tag [static] the parameters that must have actual data
loaded into them before <code>vxVerifyGraph()</code>.</p>
</div>
</div>
<div class="sect2">
<h3 id="sec_kernel_names">1.5. Kernel names</h3>
<div class="paragraph">
<p>When using <code>vxGetKernelByName</code> the following are strings specifying the
Neural Networks extension kernel names:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>org.khronos.nn_extension.convolution_layer</p>
</li>
<li>
<p>org.khronos.nn_extension.fully_connected_layer</p>
</li>
<li>
<p>org.khronos.nn_extension.pooling_layer</p>
</li>
<li>
<p>org.khronos.nn_extension.softmax_layer</p>
</li>
<li>
<p>org.khronos.nn_extension.local_response_normalization_layer</p>
</li>
<li>
<p>org.khronos.nn_extension.activation_layer</p>
</li>
<li>
<p>org.khronos.nn_extension.roi_pooling_layer</p>
</li>
<li>
<p>org.khronos.nn_extension.deconvolution_layer</p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="sec_extensions">1.6. 8-bit extension and 16-bit extension</h3>
<div class="paragraph">
<p>The Neural Network Extension is actually two different extensions.
Neural Network 16-bit extension and Neural Network 8-bit extension.
The 8-bit extension is required.
The 16-bit extension is optional.
For 8-bit extension, <code><a href="#VX_TYPE_UINT8">VX_TYPE_UINT8</a></code> and <code><a href="#VX_TYPE_INT8">VX_TYPE_INT8</a></code>, with
fixed_point_position 0, must be supported for all functions.
For 16-bit extension, <code><a href="#VX_TYPE_INT16">VX_TYPE_INT16</a></code> with fixed_point_position 8, must
be supported for all functions.
The users can query <code><a href="#VX_CONTEXT_EXTENSIONS">VX_CONTEXT_EXTENSIONS</a></code>, the extension strings are
returned to identify two extensions.
Implementations must return the 8-bit extension string, and may return the
16-bit extension string.
If implementations return the 16-bit extension string, the 8-bit extension
string must be returned as well.
The 8-bit extension string is <code>"KHR_NN_8"</code> and the 16-bit extension string is
<code>"KHR_NN_16"</code>.
The legal string combinations are <code>"KHR_NN_8"</code> or <code>"KHR_NN_8 KHR_NN_16"</code>.</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="module_documentation">2. Module Documentation</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="group_cnn">2.1. Extension: Deep Convolutional Networks API</h3>
<div class="paragraph">
<p>Convolutional Network Nodes</p>
</div>
<div class="paragraph">
<p><strong>Data Structures</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p><code><a href="#vx_nn_convolution_params_t">vx_nn_convolution_params_t</a></code></p>
</li>
<li>
<p><code><a href="#vx_nn_deconvolution_params_t">vx_nn_deconvolution_params_t</a></code></p>
</li>
<li>
<p><code><a href="#vx_nn_roi_pool_params_t">vx_nn_roi_pool_params_t</a></code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Macros</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p><code><a href="#VX_LIBRARY_KHR_NN_EXTENSION">VX_LIBRARY_KHR_NN_EXTENSION</a></code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Enumerations</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p><code><a href="#vx_kernel_nn_ext_e">vx_kernel_nn_ext_e</a></code></p>
</li>
<li>
<p><code><a href="#vx_nn_activation_function_e">vx_nn_activation_function_e</a></code></p>
</li>
<li>
<p><code><a href="#vx_nn_enum_e">vx_nn_enum_e</a></code></p>
</li>
<li>
<p><code><a href="#vx_nn_norm_type_e">vx_nn_norm_type_e</a></code></p>
</li>
<li>
<p><code><a href="#vx_nn_pooling_type_e">vx_nn_pooling_type_e</a></code></p>
</li>
<li>
<p><code><a href="#vx_nn_rounding_type_e">vx_nn_rounding_type_e</a></code></p>
</li>
<li>
<p><code><a href="#vx_nn_type_e">vx_nn_type_e</a></code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Functions</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p><code><a href="#vxActivationLayer">vxActivationLayer</a></code></p>
</li>
<li>
<p><code><a href="#vxConvolutionLayer">vxConvolutionLayer</a></code></p>
</li>
<li>
<p><code><a href="#vxDeconvolutionLayer">vxDeconvolutionLayer</a></code></p>
</li>
<li>
<p><code><a href="#vxFullyConnectedLayer">vxFullyConnectedLayer</a></code></p>
</li>
<li>
<p><code><a href="#vxLocalResponseNormalizationLayer">vxLocalResponseNormalizationLayer</a></code></p>
</li>
<li>
<p><code><a href="#vxPoolingLayer">vxPoolingLayer</a></code></p>
</li>
<li>
<p><code><a href="#vxROIPoolingLayer">vxROIPoolingLayer</a></code></p>
</li>
<li>
<p><code><a href="#vxSoftmaxLayer">vxSoftmaxLayer</a></code></p>
</li>
</ul>
</div>
<div class="sect3">
<h4 id="_data_structures">2.1.1. Data Structures</h4>
<div class="sect4">
<h5 id="_vx_nn_convolution_params_t">vx_nn_convolution_params_t</h5>
<div class="paragraph">
<p>Input parameters for a convolution operation.</p>
</div>
<div id="vx_nn_convolution_params_t" class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c"><span class="keyword">typedef</span> <span class="keyword">struct</span> _vx_nn_convolution_params_t {
    vx_size    padding_x;
    vx_size    padding_y;
    vx_enum    overflow_policy;
    vx_enum    rounding_policy;
    vx_enum    down_scale_size_rounding;
    vx_size    dilation_x;
    vx_size    dilation_y;
} vx_nn_convolution_params_t;</code></pre>
</div>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 25%;">
<col style="width: 75%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-middle">Data Field</th>
<th class="tableblock halign-left valign-middle">Definition</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-middle"><p class="tableblock">dilation_x</p></td>
<td class="tableblock halign-left valign-middle"><p class="tableblock">“inflate” the kernel by inserting zeros between the kernel elements in the x direction. The value is the number of zeros to insert.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-middle"><p class="tableblock">dilation_y</p></td>
<td class="tableblock halign-left valign-middle"><p class="tableblock">“inflate” the kernel by inserting zeros between the kernel elements in the y direction. The value is the number of zeros to insert.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-middle"><p class="tableblock">down_scale_size_rounding</p></td>
<td class="tableblock halign-left valign-middle"><p class="tableblock">Rounding method for calculating output dimensions. See <a href="#vx_nn_rounding_type_e">vx_nn_rounding_type_e</a>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-middle"><p class="tableblock">overflow_policy</p></td>
<td class="tableblock halign-left valign-middle"><p class="tableblock">A VX_TYPE_ENUM of the vx_convert_policy_e enumeration.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-middle"><p class="tableblock">padding_x</p></td>
<td class="tableblock halign-left valign-middle"><p class="tableblock">Number of elements added at each side in the x dimension of the input.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-middle"><p class="tableblock">padding_y</p></td>
<td class="tableblock halign-left valign-middle"><p class="tableblock">Number of elements added at each side in the y dimension of the input.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-middle"><p class="tableblock">rounding_policy</p></td>
<td class="tableblock halign-left valign-middle"><p class="tableblock">A VX_TYPE_ENUM of the vx_round_policy_e enumeration.</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect4">
<h5 id="_vx_nn_deconvolution_params_t">vx_nn_deconvolution_params_t</h5>
<div class="paragraph">
<p>Input parameters for a deconvolution operation.</p>
</div>
<div id="vx_nn_deconvolution_params_t" class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c"><span class="keyword">typedef</span> <span class="keyword">struct</span> _vx_nn_deconvolution_params_t {
    vx_size    padding_x;
    vx_size    padding_y;
    vx_enum    overflow_policy;
    vx_enum    rounding_policy;
    vx_size    a_x;
    vx_size    a_y;
} vx_nn_deconvolution_params_t;</code></pre>
</div>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 25%;">
<col style="width: 75%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-middle">Data Field</th>
<th class="tableblock halign-left valign-middle">Definition</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-middle"><p class="tableblock">a_x</p></td>
<td class="tableblock halign-left valign-middle"><p class="tableblock">user-specified quantity used to distinguish between the <em><span class="eq">upscale<sub>x</sub></span></em> different possible output sizes.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-middle"><p class="tableblock">a_y</p></td>
<td class="tableblock halign-left valign-middle"><p class="tableblock">user-specified quantity used to distinguish between the <em><span class="eq">upscale<sub>y</sub></span></em> different possible output sizes.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-middle"><p class="tableblock">overflow_policy</p></td>
<td class="tableblock halign-left valign-middle"><p class="tableblock">A VX_TYPE_ENUM of the vx_convert_policy_e enumeration.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-middle"><p class="tableblock">padding_x</p></td>
<td class="tableblock halign-left valign-middle"><p class="tableblock">Number of elements subtracted at each side in the x dimension of the output.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-middle"><p class="tableblock">padding_y</p></td>
<td class="tableblock halign-left valign-middle"><p class="tableblock">Number of elements subtracted at each side in the y dimension of the output.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-middle"><p class="tableblock">rounding_policy</p></td>
<td class="tableblock halign-left valign-middle"><p class="tableblock">A VX_TYPE_ENUM of the vx_round_policy_e enumeration.</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect4">
<h5 id="_vx_nn_roi_pool_params_t">vx_nn_roi_pool_params_t</h5>
<div class="paragraph">
<p>Input parameters for ROI pooling operation.</p>
</div>
<div id="vx_nn_roi_pool_params_t" class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c"><span class="keyword">typedef</span> <span class="keyword">struct</span> _vx_nn_roi_pool_params_t {
    vx_enum    pool_type;
} vx_nn_roi_pool_params_t;</code></pre>
</div>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 25%;">
<col style="width: 75%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-middle">Data Field</th>
<th class="tableblock halign-left valign-middle">Definition</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-middle"><p class="tableblock">pool_type</p></td>
<td class="tableblock halign-left valign-middle"><p class="tableblock">Of type <a href="#vx_nn_pooling_type_e">vx_nn_pooling_type_e</a>. Only <a href="#VX_NN_POOLING_MAX">VX_NN_POOLING_MAX</a> pooling is supported.</p></td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="sect3">
<h4 id="_macros">2.1.2. Macros</h4>
<div class="sect4">
<h5 id="_vx_library_khr_nn_extension">VX_LIBRARY_KHR_NN_EXTENSION</h5>
<div class="paragraph">
<p>The Neural Network Extension Library Set.</p>
</div>
<div id="VX_LIBRARY_KHR_NN_EXTENSION" class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c"><span class="preprocessor">#define</span> VX_LIBRARY_KHR_NN_EXTENSION       (<span class="hex">0x1</span>)</code></pre>
</div>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_enumerations">2.1.3. Enumerations</h4>
<div class="sect4">
<h5 id="_vx_kernel_nn_ext_e">vx_kernel_nn_ext_e</h5>
<div class="paragraph">
<p>The list of Neural Network Extension Kernels.</p>
</div>
<div id="vx_kernel_nn_ext_e" class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c"><span class="keyword">enum</span> vx_kernel_nn_ext_e {
    VX_KERNEL_CONVOLUTION_LAYER = VX_KERNEL_BASE(VX_ID_KHRONOS, VX_LIBRARY_KHR_NN_EXTENSION) + <span class="hex">0x0</span>,
    VX_KERNEL_FULLY_CONNECTED_LAYER = VX_KERNEL_BASE(VX_ID_KHRONOS, VX_LIBRARY_KHR_NN_EXTENSION) + <span class="hex">0x1</span>,
    VX_KERNEL_POOLING_LAYER = VX_KERNEL_BASE(VX_ID_KHRONOS, VX_LIBRARY_KHR_NN_EXTENSION) + <span class="hex">0x2</span>,
    VX_KERNEL_SOFTMAX_LAYER = VX_KERNEL_BASE(VX_ID_KHRONOS, VX_LIBRARY_KHR_NN_EXTENSION) + <span class="hex">0x3</span>,
    VX_KERNEL_NORMALIZATION_LAYER = VX_KERNEL_BASE(VX_ID_KHRONOS, VX_LIBRARY_KHR_NN_EXTENSION) + <span class="hex">0x4</span>,
    VX_KERNEL_ACTIVATION_LAYER = VX_KERNEL_BASE(VX_ID_KHRONOS, VX_LIBRARY_KHR_NN_EXTENSION) + <span class="hex">0x5</span>,
    VX_KERNEL_ROI_POOLING_LAYER = VX_KERNEL_BASE(VX_ID_KHRONOS, VX_LIBRARY_KHR_NN_EXTENSION) + <span class="hex">0x6</span>,
    VX_KERNEL_DECONVOLUTION_LAYER = VX_KERNEL_BASE(VX_ID_KHRONOS, VX_LIBRARY_KHR_NN_EXTENSION) + <span class="hex">0x7</span>,
    VX_KERNEL_LOCAL_RESPONSE_NORMALIZATION_LAYER = VX_KERNEL_BASE(VX_ID_KHRONOS, VX_LIBRARY_KHR_NN_EXTENSION) + <span class="hex">0x8</span>,
};</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Enumerator</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p><a id="VX_KERNEL_CONVOLUTION_LAYER"></a> <code>VX_KERNEL_CONVOLUTION_LAYER</code> - The
Neural Network Extension convolution Kernel.</p>
<div class="openblock">
<div class="content">
<div class="paragraph">
<p><strong>See also:</strong> <a href="#group_cnn">Extension: Deep Convolutional Networks API</a></p>
</div>
</div>
</div>
</li>
<li>
<p><a id="VX_KERNEL_FULLY_CONNECTED_LAYER"></a> <code>VX_KERNEL_FULLY_CONNECTED_LAYER</code> -
The Neural Network Extension fully connected Kernel.</p>
<div class="openblock">
<div class="content">
<div class="paragraph">
<p><strong>See also:</strong> <a href="#group_cnn">Extension: Deep Convolutional Networks API</a></p>
</div>
</div>
</div>
</li>
<li>
<p><a id="VX_KERNEL_POOLING_LAYER"></a> <code>VX_KERNEL_POOLING_LAYER</code> - The Neural
Network Extension pooling Kernel.</p>
<div class="openblock">
<div class="content">
<div class="paragraph">
<p><strong>See also:</strong> <a href="#group_cnn">Extension: Deep Convolutional Networks API</a></p>
</div>
</div>
</div>
</li>
<li>
<p><a id="VX_KERNEL_SOFTMAX_LAYER"></a> <code>VX_KERNEL_SOFTMAX_LAYER</code> - The Neural
Network Extension softmax Kernel.</p>
<div class="openblock">
<div class="content">
<div class="paragraph">
<p><strong>See also:</strong> <a href="#group_cnn">Extension: Deep Convolutional Networks API</a></p>
</div>
</div>
</div>
</li>
<li>
<p><a id="VX_KERNEL_LOCAL_RESPONSE_NORMALIZATION_LAYER"></a> <code>VX_KERNEL_LOCAL_RESPONSE_NORMALIZATION_LAYER</code> - The
Neural Network Extension Local Response Normalization Kernel.</p>
<div class="openblock">
<div class="content">
<div class="paragraph">
<p><strong>See also:</strong> <a href="#group_cnn">Extension: Deep Convolutional Networks API</a></p>
</div>
</div>
</div>
</li>
<li>
<p><a id="VX_KERNEL_ACTIVATION_LAYER"></a> <code>VX_KERNEL_ACTIVATION_LAYER</code> - The Neural
Network Extension activation Kernel.</p>
<div class="openblock">
<div class="content">
<div class="paragraph">
<p><strong>See also:</strong> <a href="#group_cnn">Extension: Deep Convolutional Networks API</a></p>
</div>
</div>
</div>
</li>
<li>
<p><a id="VX_KERNEL_ROI_POOLING_LAYER"></a> <code>VX_KERNEL_ROI_POOLING_LAYER</code> - The
Neural Network POI Pooling Kernel.</p>
<div class="openblock">
<div class="content">
<div class="paragraph">
<p><strong>See also:</strong> <a href="#group_cnn">Extension: Deep Convolutional Networks API</a></p>
</div>
</div>
</div>
</li>
<li>
<p><a id="VX_KERNEL_DECONVOLUTION_LAYER"></a> <code>VX_KERNEL_DECONVOLUTION_LAYER</code> - The
Neural Network Extension Deconvolution Kernel.</p>
<div class="openblock">
<div class="content">
<div class="paragraph">
<p><strong>See also:</strong> <a href="#group_cnn">Extension: Deep Convolutional Networks API</a></p>
</div>
</div>
</div>
</li>
</ul>
</div>
</div>
<div class="sect4">
<h5 id="_vx_nn_activation_function_e">vx_nn_activation_function_e</h5>
<div class="paragraph">
<p>The Neural Network activation functions list.</p>
</div>
<div id="vx_nn_activation_function_e" class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c"><span class="keyword">enum</span> vx_nn_activation_function_e {
    VX_NN_ACTIVATION_LOGISTIC = VX_ENUM_BASE(VX_ID_KHRONOS, VX_ENUM_NN_ACTIVATION_FUNCTION_TYPE) + <span class="hex">0x0</span>,
    VX_NN_ACTIVATION_HYPERBOLIC_TAN = VX_ENUM_BASE(VX_ID_KHRONOS, VX_ENUM_NN_ACTIVATION_FUNCTION_TYPE) + <span class="hex">0x1</span>,
    VX_NN_ACTIVATION_RELU = VX_ENUM_BASE(VX_ID_KHRONOS, VX_ENUM_NN_ACTIVATION_FUNCTION_TYPE) + <span class="hex">0x2</span>,
    VX_NN_ACTIVATION_BRELU = VX_ENUM_BASE(VX_ID_KHRONOS, VX_ENUM_NN_ACTIVATION_FUNCTION_TYPE) + <span class="hex">0x3</span>,
    VX_NN_ACTIVATION_SOFTRELU = VX_ENUM_BASE(VX_ID_KHRONOS, VX_ENUM_NN_ACTIVATION_FUNCTION_TYPE) + <span class="hex">0x4</span>,
    VX_NN_ACTIVATION_ABS = VX_ENUM_BASE(VX_ID_KHRONOS, VX_ENUM_NN_ACTIVATION_FUNCTION_TYPE) + <span class="hex">0x5</span>,
    VX_NN_ACTIVATION_SQUARE = VX_ENUM_BASE(VX_ID_KHRONOS, VX_ENUM_NN_ACTIVATION_FUNCTION_TYPE) + <span class="hex">0x6</span>,
    VX_NN_ACTIVATION_SQRT = VX_ENUM_BASE(VX_ID_KHRONOS, VX_ENUM_NN_ACTIVATION_FUNCTION_TYPE) + <span class="hex">0x7</span>,
    VX_NN_ACTIVATION_LINEAR = VX_ENUM_BASE(VX_ID_KHRONOS, VX_ENUM_NN_ACTIVATION_FUNCTION_TYPE) + <span class="hex">0x8</span>,
};</code></pre>
</div>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Function Name</th>
<th class="tableblock halign-left valign-top">Mathematical definition</th>
<th class="tableblock halign-left valign-top">Parameters</th>
<th class="tableblock halign-left valign-top">Parameters type</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">logistic</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="eq">f(x) = 1 / (1+e<sup>-x</sup>)</span></p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">hyperbolic tangent</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="eq">f(x) = a ⋅ tanh(b ⋅ x)</span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">a, b</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code><a href="#VX_FLOAT32">VX_FLOAT32</a></code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">relu</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="eq">f(x) = max(0,x)</span></p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">bounded relu</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="eq">f(x) = min(a, max(0,x))</span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">a</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code><a href="#VX_FLOAT32">VX_FLOAT32</a></code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">soft relu</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="eq">f(x) = log(1 + e<sup>x</sup>)</span></p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">abs</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="eq">f(x) = | x |</span></p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">square</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="eq">f(x) = x<sup>2</sup></span></p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">square root</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="eq">f(x) = sqrt(x)</span></p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">linear</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="eq">f(x) = a x + b</span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">a, b</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code><a href="#VX_FLOAT32">VX_FLOAT32</a></code></p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Enumerator</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p><a id="VX_NN_ACTIVATION_LOGISTIC"></a> <code>VX_NN_ACTIVATION_LOGISTIC</code></p>
</li>
<li>
<p><a id="VX_NN_ACTIVATION_HYPERBOLIC_TAN"></a> <code>VX_NN_ACTIVATION_HYPERBOLIC_TAN</code></p>
</li>
<li>
<p><a id="VX_NN_ACTIVATION_RELU"></a> <code>VX_NN_ACTIVATION_RELU</code></p>
</li>
<li>
<p><a id="VX_NN_ACTIVATION_BRELU"></a> <code>VX_NN_ACTIVATION_BRELU</code></p>
</li>
<li>
<p><a id="VX_NN_ACTIVATION_SOFTRELU"></a> <code>VX_NN_ACTIVATION_SOFTRELU</code></p>
</li>
<li>
<p><a id="VX_NN_ACTIVATION_ABS"></a> <code>VX_NN_ACTIVATION_ABS</code></p>
</li>
<li>
<p><a id="VX_NN_ACTIVATION_SQUARE"></a> <code>VX_NN_ACTIVATION_SQUARE</code></p>
</li>
<li>
<p><a id="VX_NN_ACTIVATION_SQRT"></a> <code>VX_NN_ACTIVATION_SQRT</code></p>
</li>
<li>
<p><a id="VX_NN_ACTIVATION_LINEAR"></a> <code>VX_NN_ACTIVATION_LINEAR</code></p>
</li>
</ul>
</div>
</div>
<div class="sect4">
<h5 id="_vx_nn_enum_e">vx_nn_enum_e</h5>
<div class="paragraph">
<p>NN extension type enums.</p>
</div>
<div id="vx_nn_enum_e" class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c"><span class="keyword">enum</span> vx_nn_enum_e {
    VX_ENUM_NN_ROUNDING_TYPE = <span class="hex">0x1A</span>,
    VX_ENUM_NN_POOLING_TYPE = <span class="hex">0x1B</span>,
    VX_ENUM_NN_NORMALIZATION_TYPE = <span class="hex">0x1C</span>,
    VX_ENUM_NN_ACTIVATION_FUNCTION_TYPE = <span class="hex">0x1D</span>,
};</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Enumerator</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p><a id="VX_ENUM_NN_ROUNDING_TYPE"></a> <code>VX_ENUM_NN_ROUNDING_TYPE</code></p>
</li>
<li>
<p><a id="VX_ENUM_NN_POOLING_TYPE"></a> <code>VX_ENUM_NN_POOLING_TYPE</code></p>
</li>
<li>
<p><a id="VX_ENUM_NN_NORMALIZATION_TYPE"></a> <code>VX_ENUM_NN_NORMALIZATION_TYPE</code></p>
</li>
<li>
<p><a id="VX_ENUM_NN_ACTIVATION_FUNCTION_TYPE"></a>
<code>VX_ENUM_NN_ACTIVATION_FUNCTION_TYPE</code></p>
</li>
</ul>
</div>
</div>
<div class="sect4">
<h5 id="_vx_nn_norm_type_e">vx_nn_norm_type_e</h5>
<div class="paragraph">
<p>The Neural Network normalization type list.</p>
</div>
<div id="vx_nn_norm_type_e" class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c"><span class="keyword">enum</span> vx_nn_norm_type_e {
    VX_NN_NORMALIZATION_SAME_MAP = VX_ENUM_BASE(VX_ID_KHRONOS, VX_ENUM_NN_NORMALIZATION_TYPE) + <span class="hex">0x0</span>,
    VX_NN_NORMALIZATION_ACROSS_MAPS = VX_ENUM_BASE(VX_ID_KHRONOS, VX_ENUM_NN_NORMALIZATION_TYPE) + <span class="hex">0x1</span>,
};</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Enumerator</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p><a id="VX_NN_NORMALIZATION_SAME_MAP"></a> <code>VX_NN_NORMALIZATION_SAME_MAP</code> -
normalization is done on same IFM</p>
</li>
<li>
<p><a id="VX_NN_NORMALIZATION_ACROSS_MAPS"></a> <code>VX_NN_NORMALIZATION_ACROSS_MAPS</code> -
Normalization is done across different IFMs.</p>
</li>
</ul>
</div>
</div>
<div class="sect4">
<h5 id="_vx_nn_pooling_type_e">vx_nn_pooling_type_e</h5>
<div class="paragraph">
<p>The Neural Network pooling type list.</p>
</div>
<div id="vx_nn_pooling_type_e" class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c"><span class="keyword">enum</span> vx_nn_pooling_type_e {
    VX_NN_POOLING_MAX = VX_ENUM_BASE(VX_ID_KHRONOS, VX_ENUM_NN_POOLING_TYPE) + <span class="hex">0x0</span>,
    VX_NN_POOLING_AVG = VX_ENUM_BASE(VX_ID_KHRONOS, VX_ENUM_NN_POOLING_TYPE) + <span class="hex">0x1</span>,
};</code></pre>
</div>
</div>
<div class="paragraph">
<p>kind of pooling done in pooling function</p>
</div>
<div class="paragraph">
<p><strong>Enumerator</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p><a id="VX_NN_POOLING_MAX"></a> <code>VX_NN_POOLING_MAX</code> - max pooling</p>
</li>
<li>
<p><a id="VX_NN_POOLING_AVG"></a> <code>VX_NN_POOLING_AVG</code> - average pooling</p>
</li>
</ul>
</div>
</div>
<div class="sect4">
<h5 id="_vx_nn_rounding_type_e">vx_nn_rounding_type_e</h5>
<div class="paragraph">
<p>down scale rounding.</p>
</div>
<div id="vx_nn_rounding_type_e" class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c"><span class="keyword">enum</span> vx_nn_rounding_type_e {
    VX_NN_DS_SIZE_ROUNDING_FLOOR = VX_ENUM_BASE(VX_ID_KHRONOS, VX_ENUM_NN_ROUNDING_TYPE) + <span class="hex">0x0</span>,
    VX_NN_DS_SIZE_ROUNDING_CEILING = VX_ENUM_BASE(VX_ID_KHRONOS, VX_ENUM_NN_ROUNDING_TYPE) + <span class="hex">0x1</span>,
};</code></pre>
</div>
</div>
<div class="paragraph">
<p>Due to different scheme of downscale size calculation in the various
training frameworks.
Implementation must support 2 rounding methods for down scale calculation.
The floor and the ceiling.
In convolution and pooling functions.
Relevant when input size is even.</p>
</div>
<div class="paragraph">
<p><strong>Enumerator</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p><a id="VX_NN_DS_SIZE_ROUNDING_FLOOR"></a> <code>VX_NN_DS_SIZE_ROUNDING_FLOOR</code> - floor
rounding</p>
</li>
<li>
<p><a id="VX_NN_DS_SIZE_ROUNDING_CEILING"></a> <code>VX_NN_DS_SIZE_ROUNDING_CEILING</code> -
ceil rounding</p>
</li>
</ul>
</div>
</div>
<div class="sect4">
<h5 id="_vx_nn_type_e">vx_nn_type_e</h5>
<div class="paragraph">
<p>The type enumeration lists all NN extension types.</p>
</div>
<div id="vx_nn_type_e" class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c"><span class="keyword">enum</span> vx_nn_type_e {
    VX_TYPE_NN_CONVOLUTION_PARAMS = <span class="hex">0x025</span>,
    VX_TYPE_NN_DECONVOLUTION_PARAMS = <span class="hex">0x026</span>,
    VX_TYPE_NN_ROI_POOL_PARAMS = <span class="hex">0x027</span>,
};</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Enumerator</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p><a id="VX_TYPE_NN_CONVOLUTION_PARAMS"></a> <code>VX_TYPE_NN_CONVOLUTION_PARAMS</code> - A
<code><a href="#vx_nn_convolution_params_t">vx_nn_convolution_params_t</a></code>.</p>
</li>
<li>
<p><a id="VX_TYPE_NN_DECONVOLUTION_PARAMS"></a> <code>VX_TYPE_NN_DECONVOLUTION_PARAMS</code> -
A <code><a href="#vx_nn_deconvolution_params_t">vx_nn_deconvolution_params_t</a></code>.</p>
</li>
<li>
<p><a id="VX_TYPE_NN_ROI_POOL_PARAMS"></a> <code>VX_TYPE_NN_ROI_POOL_PARAMS</code> - A
<code><a href="#vx_nn_roi_pool_params_t">vx_nn_roi_pool_params_t</a></code>.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_functions">2.1.4. Functions</h4>
<div class="sect4">
<h5 id="_vxactivationlayer">vxActivationLayer</h5>
<div class="paragraph">
<p>[Graph] Creates a Convolutional Network Activation Layer Node.
The function operate a specific function (Specified in
<code><a href="#vx_nn_activation_function_e">vx_nn_activation_function_e</a></code>), On the input data.
the equation for the layer is:</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1"></dt>
<dd>
<p><span class="eq">outputs(i,j,k,l) = function(inputs(i,j,k,l), a, b)</span></p>
</dd>
</dl>
</div>
<div class="paragraph">
<p>for all i,j,k,l.</p>
</div>
<div id="vxActivationLayer" class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c">vx_node vxActivationLayer(
    vx_graph                                    graph,
    vx_tensor                                   inputs,
    vx_enum                                     function,
    vx_float32                                  a,
    vx_float32                                  b,
    vx_tensor                                   outputs);</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Parameters</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>[in]</code> <em>graph</em> - The handle to the graph.</p>
</li>
<li>
<p><code>[in]</code> <em>inputs</em> - The input tensor data.
Implementations must support input tensor data types indicated by the
extension strings <code>"KHR_NN_8"</code> or <code>"KHR_NN_8 KHR_NN_16"</code>.</p>
</li>
<li>
<p><code>[in]</code> <em>function</em> - [static] Non-linear function (see
<code><a href="#vx_nn_activation_function_e">vx_nn_activation_function_e</a></code>).
Implementations must support <code>VX_NN_ACTIVATION_LOGISTIC</code>,
<code>VX_NN_ACTIVATION_HYPERBOLIC_TAN</code> and <code>VX_NN_ACTIVATION_RELU</code></p>
</li>
<li>
<p><code>[in]</code> <em>a</em> - [static] Function parameters a.
must be positive.</p>
</li>
<li>
<p><code>[in]</code> <em>b</em> - [static] Function parameters b.
must be positive.</p>
</li>
<li>
<p><code>[out]</code> <em>outputs</em> - The output tensor data.
Output will have the same number of dimensions as input.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Returns:</strong> A node reference <code>vx_node</code>.
Any possible errors preventing a successful creation should be checked using
<code>vxGetStatus</code>.</p>
</div>
</div>
<div class="sect4">
<h5 id="_vxconvolutionlayer">vxConvolutionLayer</h5>
<div class="paragraph">
<p>[Graph] Creates a Convolutional Network Convolution Layer Node.</p>
</div>
<div id="vxConvolutionLayer" class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c">vx_node vxConvolutionLayer(
    vx_graph                                    graph,
    vx_tensor                                   inputs,
    vx_tensor                                   weights,
    vx_tensor                                   biases,
    <span class="directive">const</span> vx_nn_convolution_params_t*           convolution_params,
    vx_size                                     size_of_convolution_params,
    vx_tensor                                   outputs);</code></pre>
</div>
</div>
<div class="paragraph">
<p>This function implement Convolutional Network Convolution layer.
For fixed-point data types, a fixed point calculation is performed with
round and saturate according to the number of accumulator bits.
The number of the accumulator bits are implementation defined, and should be
at least 16.</p>
</div>
<div class="paragraph">
<p>round: rounding according the <code>vx_round_policy_e</code> enumeration.</p>
</div>
<div class="paragraph">
<p>saturate: A saturation according the <code>vx_convert_policy_e</code> enumeration.
The following equation is implemented:</p>
</div>
<div class="paragraph">
<p>\(outputs[j,k,i] = saturate(round(\sum_{l} (\sum_{m,n}
           inputs[j+m,k+n,l] \times weights[m,n,l,i]) +
           biasses[j,k,i]))\)</p>
</div>
<div class="paragraph">
<p>Where <span class="eq">(m, n)</span> are indexes on the convolution matrices.
<span class="eq">l</span> is an index on all the convolutions per input.
<span class="eq">i</span> is an index per output.
<span class="eq">(j, k)</span> are the inputs/outputs spatial indexes.
Convolution is done on the width and height dimensions of the <code>vx_tensor</code>.
Therefore, we use here the term x for index along the width dimension and y
for index along the height dimension.</p>
</div>
<div class="paragraph">
<p>Before the Convolution is done, a padding with zeros of the width and height
input dimensions is performed.
Then down scale is done by picking the results according to a skip jump.
The skip in the x and y is determined by the output size dimensions.
The relation between input to output is as follows:</p>
</div>
<div class="paragraph">
<p>\(width_{output} = round(\frac{(width_{input} + 2 * padding_x -
kernel_x - (kernel_x - 1) * dilation_x)}{skip_x} + 1)\)</p>
</div>
<div class="paragraph">
<p>and</p>
</div>
<div class="paragraph">
<p>\(height_{output} = round(\frac{(height + 2 * padding_y - kernel_y
- (kernel_y - 1) * dilation_y)}{skip_y} + 1)\)</p>
</div>
<div class="paragraph">
<p>where <span class="eq">width</span> is the size of the input width dimension.
<span class="eq">height</span> is the size of the input height dimension.
<span class="eq">width<sub>output</sub></span> is the size of the output width dimension.
<span class="eq">height<sub>output</sub></span> is the size of the output height dimension.
<span class="eq">kernel<sub>x</sub></span> and <span class="eq">kernel<sub>y</sub></span> are the convolution sizes in width and
height dimensions.
skip is calculated by the relation between input and output.
In case of ambiguity in the inverse calculation of the skip.
The minimum solution is chosen.
Skip must be a positive non zero integer.
rounding is done according to <code><a href="#vx_nn_rounding_type_e">vx_nn_rounding_type_e</a></code>.
Notice that this node creation function has more parameters than the
corresponding kernel.
Numbering of kernel parameters (required if you create this node using the
generic interface) is explicitly specified here.</p>
</div>
<div class="paragraph">
<p><strong>Parameters</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>[in]</code> <em>graph</em> - The handle to the graph.</p>
</li>
<li>
<p><code>[in]</code> <em>inputs</em> - The input tensor data.
3 lower dimensions represent a single input, all following dimensions
represent number of batches, possibly nested.
The dimension order is [width, height, #IFM, #batches]</p>
<div class="openblock">
<div class="content">
<div class="paragraph">
<p>Implementations must support input tensor data types indicated by the
extension strings <code>"KHR_NN_8"</code> or <code>"KHR_NN_8 KHR_NN_16"</code>.
(Kernel parameter #0)</p>
</div>
</div>
</div>
</li>
<li>
<p><code>[in]</code> <em>weights</em> - [static] Weights are 4d tensor with dimensions
[kernel_x, kernel_y, #IFM, #OFM].
see <code>vxCreateTensor</code> and <code>vxCreateVirtualTensor</code></p>
<div class="openblock">
<div class="content">
<div class="paragraph">
<p>Weights data type must match the data type of the inputs.
(Kernel parameter #1)</p>
</div>
</div>
</div>
</li>
<li>
<p><code>[in]</code> <em>biases</em> - [static] Optional, ignored if NULL.
The biases, which may be shared (one per ofm) or unshared (one per ofm *
output location).
The possible layouts are either [#OFM] or [width, height, #OFM].
Biases data type must match the data type of the inputs.
(Kernel parameter #2)</p>
</li>
<li>
<p><code>[in]</code> <em>convolution_params</em> - [static] Pointer to parameters of type
<code><a href="#vx_nn_convolution_params_t">vx_nn_convolution_params_t</a></code>.
(Kernel parameter #3)</p>
</li>
<li>
<p><code>[in]</code> <em>size_of_convolution_params</em> - [static] Size in bytes of
convolution_params.
Note that this parameter is not counted as one of the kernel parameters.</p>
</li>
<li>
<p><code>[out]</code> <em>outputs</em> - The output tensor data.
Output will have the same number and structure of dimensions as input.
Output tensor data type must be same as the inputs.
(Kernel parameter #4)</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Returns:</strong> A node reference <code>vx_node</code>.
Any possible errors preventing a successful creation should be checked using
<code>vxGetStatus</code>.</p>
</div>
</div>
<div class="sect4">
<h5 id="_vxdeconvolutionlayer">vxDeconvolutionLayer</h5>
<div class="paragraph">
<p>[Graph] Creates a Convolutional Network Deconvolution Layer Node.</p>
</div>
<div id="vxDeconvolutionLayer" class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c">vx_node vxDeconvolutionLayer(
    vx_graph                                    graph,
    vx_tensor                                   inputs,
    vx_tensor                                   weights,
    vx_tensor                                   biases,
    <span class="directive">const</span> vx_nn_deconvolution_params_t*         deconvolution_params,
    vx_size                                     size_of_deconv_params,
    vx_tensor                                   outputs);</code></pre>
</div>
</div>
<div class="paragraph">
<p>Deconvolution denote a sort of reverse convolution, which importantly and
confusingly is not actually a proper mathematical deconvolution.
Convolutional Network Deconvolution is up-sampling of an image by learned
Deconvolution coefficients.
The operation is similar to convolution but can be implemented by
up-sampling the inputs with zeros insertions between the inputs, and
convolving the Deconvolution kernels on the up-sampled result.
For fixed-point data types, a fixed point calculation is performed with
round and saturate according to the number of accumulator bits.
The number of the accumulator bits are implementation defined, and should be
at least 16.</p>
</div>
<div class="paragraph">
<p>round: rounding according the <code>vx_round_policy_e</code> enumeration.</p>
</div>
<div class="paragraph">
<p>saturate: A saturation according the <code>vx_convert_policy_e</code> enumeration.
The following equation is implemented:</p>
</div>
<div class="paragraph">
<p>\(outputs[j,k,i] = saturate(round(\sum_{l}
           \sum_{m,n}(inputs_{upscaled}[j+m,k+n,l] \times
           weights[m,n,l,i]) + biasses[j,k,i]))\)</p>
</div>
<div class="paragraph">
<p>Where <span class="eq">(m, n)</span> are indexes on the convolution matrices.
<span class="eq">l</span> is an index on all the convolutions per input.
<span class="eq">i</span> is an index per output.
<span class="eq">(j, k)</span> are the inputs/outputs spatial indexes.
Deconvolution is done on the width and height dimensions of the <code>vx_tensor</code>.
Therefore, we use here the term x for the width dimension and y for the
height dimension.</p>
</div>
<div class="paragraph">
<p>before the Deconvolution is done, up-scaling the width and height dimensions
with zeros is performed.
The relation between input to output is as follows:</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1"></dt>
<dd>
<p><span class="eq">width<sub>output</sub> = (width<sub>input</sub> - 1) * upscale<sub>x</sub> - 2 * padding<sub>x</sub> + kernel<sub>x</sub> + a<sub>x</sub></span></p>
</dd>
</dl>
</div>
<div class="paragraph">
<p>and</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1"></dt>
<dd>
<p><span class="eq">height<sub>output</sub> = (height<sub>input</sub> - 1) * upscale<sub>y</sub> - 2 * padding<sub>y</sub> + kernel<sub>y</sub> + a<sub>y</sub></span></p>
</dd>
</dl>
</div>
<div class="paragraph">
<p>where <span class="eq">width<sub>input</sub></span> is the size of the input width dimension.
<span class="eq">height<sub>input</sub></span> is the size of the input height dimension.
<span class="eq">width<sub>output</sub></span> is the size of the output width dimension.
<span class="eq">height<sub>output</sub></span> is the size of the output height dimension.
<span class="eq">kernel<sub>x</sub></span> and <span class="eq">kernel<sub>y</sub></span> are the convolution sizes in width and
height.
<span class="eq">a<sub>x</sub></span> and <span class="eq">a<sub>y</sub></span> are user-specified quantity used to distinguish
between the <span class="eq">upscale<sub>x</sub></span> and <span class="eq">upscale<sub>y</sub></span> different possible output
sizes.
<span class="eq">upscale<sub>x</sub></span> and <span class="eq">upscale<sub>y</sub></span> are calculated by the relation between
input and output.
<span class="eq">a<sub>x</sub></span> and <span class="eq">a<sub>y</sub></span> must be positive and smaller then <span class="eq">upscale<sub>x</sub></span>
and <span class="eq">upscale<sub>y</sub></span> respectively.
Since the padding parameter is on the output, the effective input padding
is:</p>
</div>
<div class="paragraph">
<p>\(padding_{input_x} = kernel_x -padding_x -1\)</p>
</div>
<div class="paragraph">
<p>\(padding_{input_y} = kernel_y -padding_y -1\)</p>
</div>
<div class="paragraph">
<p>Therfore the following constraints apply: <span class="eq">kernel<sub>x</sub> ≥ padding<sub>x</sub> -
1</span> and <span class="eq">kernel<sub>y</sub> ≥ padding<sub>y</sub> - 1</span>.
Rounding is done according to <code><a href="#vx_nn_rounding_type_e">vx_nn_rounding_type_e</a></code>.
Notice that this node creation function has more parameters than the
corresponding kernel.
Numbering of kernel parameters (required if you create this node using the
generic interface) is explicitly specified here.</p>
</div>
<div class="paragraph">
<p><strong>Parameters</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>[in]</code> <em>graph</em> - The handle to the graph.</p>
</li>
<li>
<p><code>[in]</code> <em>inputs</em> - The input tensor.
3 lower dimensions represent a single input, and an optional 4th
dimension for batch of inputs.
Dimension layout is [width, height, #IFM, #batches].
See <code>vxCreateTensor</code> and <code>vxCreateVirtualTensor</code>.
Implementations must support input tensor data types indicated by the
extension strings <code>"KHR_NN_8"</code> or <code>"KHR_NN_8 KHR_NN_16"</code>.
(Kernel parameter #0)</p>
</li>
<li>
<p><code>[in]</code> <em>weights</em> - [static] The 4d weights with dimensions [width, height,
#IFM, #OFM].
See <code>vxCreateTensor</code> and <code>vxCreateVirtualTensor</code>.
(Kernel parameter #1)</p>
</li>
<li>
<p><code>[in]</code> <em>biases</em> - [static] Optional, ignored if NULL.
The biases have one dimension [#OFM].
Implementations must support input tensor data type same as the inputs.
(Kernel parameter #2)</p>
</li>
<li>
<p><code>[in]</code> <em>deconvolution_params</em> - [static] Pointer to parameters of type
<code><a href="#vx_nn_deconvolution_params_t">vx_nn_deconvolution_params_t</a></code> (Kernel parameter #3)</p>
</li>
<li>
<p><code>[in]</code> <em>size_of_deconv_params</em> - [static] Size in bytes of
deconvolution_params.
Note that this parameter is not counted as one of the kernel parameters.</p>
</li>
<li>
<p><code>[out]</code> <em>outputs</em> - The output tensor.
The output has the same number of dimensions as the input.
(Kernel parameter #4)</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Returns:</strong> A node reference <code>vx_node</code>.
Any possible errors preventing a successful creation should be checked using
<code>vxGetStatus</code>.</p>
</div>
</div>
<div class="sect4">
<h5 id="_vxfullyconnectedlayer">vxFullyConnectedLayer</h5>
<div class="paragraph">
<p>[Graph] Creates a Fully connected Convolutional Network Layer Node.</p>
</div>
<div id="vxFullyConnectedLayer" class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c">vx_node vxFullyConnectedLayer(
    vx_graph                                    graph,
    vx_tensor                                   inputs,
    vx_tensor                                   weights,
    vx_tensor                                   biases,
    vx_enum                                     overflow_policy,
    vx_enum                                     rounding_policy,
    vx_tensor                                   outputs);</code></pre>
</div>
</div>
<div class="paragraph">
<p>This function implement Fully connected Convolutional Network layers.
For fixed-point data types, a fixed point calculation is performed with
round and saturate according to the number of accumulator bits.
The number of the accumulator bits are implementation defined, and should be
at least 16.</p>
</div>
<div class="paragraph">
<p>round: rounding according the <code>vx_round_policy_e</code> enumeration.</p>
</div>
<div class="paragraph">
<p>saturate: A saturation according the <code>vx_convert_policy_e</code> enumeration.
The equation for Fully connected layer:</p>
</div>
<div class="paragraph">
<p>\(outputs[i] = saturate(round(\sum_{j} (inputs[j] \times
           weights[j,i]) + biasses[i]))\)</p>
</div>
<div class="paragraph">
<p>Where <span class="eq">j</span> is a index on the input feature and <span class="eq">i</span> is a index on the
output.</p>
</div>
<div class="paragraph">
<p>There two possible input tensor layouts:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>[#IFM, #batches].
See <code>vxCreateTensor</code> and <code>vxCreateVirtualTensor</code>.</p>
</li>
<li>
<p>[width, height, #IFM, #batches].
See <code>vxCreateTensor</code> and <code>vxCreateVirtualTensor</code></p>
</li>
</ol>
</div>
<div class="paragraph">
<p>In both cases number of batches are optional and may be multidimensional.
The second option is a special case to deal with convolution layer followed
by fully connected.
The dimension order is [#IFM, #batches].
See <code>vxCreateTensor</code> and <code>vxCreateVirtualTensor</code>.
Note that batch may be multidimensional.
Implementations must support input tensor data types indicated by the
extension strings <code>"KHR_NN_8"</code> or <code>"KHR_NN_8 KHR_NN_16"</code>.</p>
</div>
<div class="paragraph">
<p><strong>Parameters</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>[in]</code> <em>graph</em> - The handle to the graph.</p>
</li>
<li>
<p><code>[in]</code> <em>inputs</em> - The input tensor data.</p>
</li>
<li>
<p><code>[in]</code> <em>weights</em> - [static] Number of dimensions is 2. Dimensions are [#IFM, #OFM].
See <code>vxCreateTensor</code> and <code>vxCreateVirtualTensor</code>.  Implementations must support input tensor data type same as the inputs.</p>
</li>
<li>
<p><code>[in]</code> <em>biases</em> - [static] Optional, ignored if NULL.
The biases have one dimension [#OFM].
Implementations must support input tensor data type same as the inputs.</p>
</li>
<li>
<p><code>[in]</code> <em>overflow_policy</em> - [static] A <code>VX_TYPE_ENUM</code> of the
<code>vx_convert_policy_e</code> enumeration.</p>
</li>
<li>
<p><code>[in]</code> <em>rounding_policy</em> - [static] A <code>VX_TYPE_ENUM</code> of the
<code>vx_round_policy_e</code> enumeration.</p>
</li>
<li>
<p><code>[out]</code> <em>outputs</em> - The output tensor data.
Output dimension layout is [#OFM,#batches].
See <code>vxCreateTensor</code> and <code>vxCreateVirtualTensor</code>, where #batches may be
multidimensional.
Output tensor data type must be same as the inputs.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Returns:</strong> A node reference <code>vx_node</code>.
Any possible errors preventing a successful creation should be checked using
<code>vxGetStatus</code>.</p>
</div>
</div>
<div class="sect4">
<h5 id="_vxlocalresponsenormalizationlayer">vxLocalResponseNormalizationLayer</h5>
<div class="paragraph">
<p>[Graph] Creates a Convolutional Network Local Response Normalization Layer Node.
This function is optional for 8-bit extension with the extension string
<code>"KHR_NN_8"</code>.</p>
</div>
<div id="vxLocalResponseNormalizationLayer" class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c">vx_node vxLocalResponseNormalizationLayer(
    vx_graph                                    graph,
    vx_tensor                                   inputs,
    vx_enum                                     type,
    vx_size                                     normalization_size,
    vx_float32                                  alpha,
    vx_float32                                  beta,
    vx_float32                                  bias,
    vx_tensor                                   outputs);</code></pre>
</div>
</div>
<div class="paragraph">
<p>Local Response Normalizing over local input regions.
Each input value is divided by</p>
</div>
<div class="paragraph">
<p>\((bias + \frac{\alpha}{n} \sum_i x^2_i)^\beta\)</p>
</div>
<div class="paragraph">
<p>where <span class="eq">n</span> is the number of elements to normalize across.
and the sum is taken over a rectangle region centred at that value (zero
padding is added where necessary).</p>
</div>
<div class="paragraph">
<p><strong>Parameters</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>[in]</code> <em>graph</em> - The handle to the graph.</p>
</li>
<li>
<p><code>[in]</code> <em>inputs</em> - The input tensor data.
3 lower dimensions represent a single input, 4th dimension for batch of
inputs is optional.Dimension layout is [width, height, IFM, #batches].
See <code>vxCreateTensor</code> and <code>vxCreateVirtualTensor</code>.
Implementations must support input tensor data types indicated by the
extension strings <code>"KHR_NN_8 KHR_NN_16"</code>.
Since this function is optional for <code>"KHR_NN_8"</code>, so implementations only
must support <code>VX_TYPE_INT16</code> with fixed_point_position 8.</p>
</li>
<li>
<p><code>[in]</code> <em>type</em> - [static] Either same map or across maps (see
<code><a href="#vx_nn_norm_type_e">vx_nn_norm_type_e</a></code>).</p>
</li>
<li>
<p><code>[in]</code> <em>normalization_size</em> - [static] Number of elements to normalize
across.
Must be a positive odd number with maximum size of 7 and minimum of 3.</p>
</li>
<li>
<p><code>[in]</code> <em>alpha</em> - [static] Alpha parameter in the local response normalization equation.
must be positive.</p>
</li>
<li>
<p><code>[in]</code> <em>beta</em> - [static] Beta parameter in the local response normalization equation.
must be positive.</p>
</li>
<li>
<p><code>[in]</code> <em>bias</em> - [static] Bias parameter in the local response normalization equation.
must be positive.</p>
</li>
<li>
<p><code>[out]</code> <em>outputs</em> - The output tensor data.
Output will have the same number of dimensions as input.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Returns:</strong> A node reference <code>vx_node</code>.
Any possible errors preventing a successful creation should be checked using
<code>vxGetStatus</code>.</p>
</div>
</div>
<div class="sect4">
<h5 id="_vxpoolinglayer">vxPoolingLayer</h5>
<div class="paragraph">
<p>[Graph] Creates a Convolutional Network Pooling Layer Node.</p>
</div>
<div id="vxPoolingLayer" class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c">vx_node vxPoolingLayer(
    vx_graph                                    graph,
    vx_tensor                                   inputs,
    vx_enum                                     pooling_type,
    vx_size                                     pooling_size_x,
    vx_size                                     pooling_size_y,
    vx_size                                     pooling_padding_x,
    vx_size                                     pooling_padding_y,
    vx_enum                                     rounding,
    vx_tensor                                   outputs);</code></pre>
</div>
</div>
<div class="paragraph">
<p>Pooling is done on the width and height dimensions of the <code>vx_tensor</code>.
Therefore, we use here the term x for the width dimension and y for the
height dimension.</p>
</div>
<div class="paragraph">
<p>Pooling operation is a function operation over a rectangle size and then a
nearest neighbour down scale.
Here we use pooling_size_x and pooling_size_y to specify the rectangle size
on which the operation is performed.</p>
</div>
<div class="paragraph">
<p>before the operation is done (average or maximum value).
the data is padded with zeros in width and height dimensions .
The down scale is done by picking the results according to a skip jump.
The skip in the x and y dimension is determined by the output size
dimensions.
The first pixel of the down scale output is the first pixel in the input.</p>
</div>
<div class="paragraph">
<p><strong>Parameters</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>[in]</code> <em>graph</em> - The handle to the graph.</p>
</li>
<li>
<p><code>[in]</code> <em>inputs</em> - The input tensor data.
3 lower dimensions represent a single input, 4th dimension for batch of
inputs is optional.Dimension layout is [width, height, #IFM, #batches].
See <code>vxCreateTensor</code> and <code>vxCreateVirtualTensor</code> Implementations must
support input tensor data types indicated by the extension strings
<code>"KHR_NN_8"</code> or <code>"KHR_NN_8 KHR_NN_16"</code>.</p>
</li>
<li>
<p><code>[in]</code> <em>pooling_type</em> - [static] Either max pooling or average pooling
(see <code><a href="#vx_nn_pooling_type_e">vx_nn_pooling_type_e</a></code>).</p>
</li>
<li>
<p><code>[in]</code> <em>pooling_size_x</em> - [static] Size of the pooling region in the x
dimension</p>
</li>
<li>
<p><code>[in]</code> <em>pooling_size_y</em> - [static] Size of the pooling region in the y
dimension.</p>
</li>
<li>
<p><code>[in]</code> <em>pooling_padding_x</em> - [static] Padding size in the x dimension.</p>
</li>
<li>
<p><code>[in]</code> <em>pooling_padding_y</em> - [static] Padding size in the y dimension.</p>
</li>
<li>
<p><code>[in]</code> <em>rounding</em> - [static] Rounding method for calculating output
dimensions.
See <code><a href="#vx_nn_rounding_type_e">vx_nn_rounding_type_e</a></code></p>
</li>
<li>
<p><code>[out]</code> <em>outputs</em> - The output tensor data.
Output will have the same number of dimensions as input.
Output tensor data type must be same as the inputs.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Returns:</strong> A node reference <code>vx_node</code>.
Any possible errors preventing a successful creation should be checked using
<code>vxGetStatus</code>.</p>
</div>
</div>
<div class="sect4">
<h5 id="_vxroipoolinglayer">vxROIPoolingLayer</h5>
<div class="paragraph">
<p>[Graph] Creates a Convolutional Network ROI pooling node</p>
</div>
<div id="vxROIPoolingLayer" class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c">vx_node vxROIPoolingLayer(
    vx_graph                                    graph,
    vx_tensor                                   input_data,
    vx_tensor                                   input_rois,
    <span class="directive">const</span> vx_nn_roi_pool_params_t*              roi_pool_params,
    vx_size                                     size_of_roi_params,
    vx_tensor                                   output_arr);</code></pre>
</div>
</div>
<div class="paragraph">
<p>Pooling is done on the width and height dimensions of the <code>vx_tensor</code>.
The ROI Pooling get an array of roi rectangles, and an input tensor.
The kernel crop the width and height dimensions of the input tensor with the
ROI rectangles and down scale the result to the size of the output tensor.
The output tensor width and height are the pooled width and pooled height.
The down scale method is determined by the pool_type.
Notice that this node creation function has more parameters than the
corresponding kernel.
Numbering of kernel parameters (required if you create this node using the
generic interface) is explicitly specified here.</p>
</div>
<div class="paragraph">
<p><strong>Parameters</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>[in]</code> <em>graph</em> - The handle to the graph.</p>
</li>
<li>
<p><code>[in]</code> <em>inputs</em> - The input tensor data.
3 lower dimensions represent a single input, 4th dimension for batch of
inputs is optional.
Dimension layout is [width, height, #IFM, #batches].
See <code>vxCreateTensor</code> and <code>vxCreateVirtualTensor</code>.
Implementations must support input tensor data types indicated by the
extension strings <code>"KHR_NN_8"</code> or <code>"KHR_NN_8 KHR_NN_16"</code>.
(Kernel parameter #0)</p>
</li>
<li>
<p><code>[in]</code> <em>inputs_rois</em> - The roi array tensor.
ROI array with dimensions [4, roi_count, #batches] where the first
dimension represents 4 coordinates of the top left and bottom right
corners of the roi rectangles, based on the input tensor width and
height.
#batches is optional and must be the same as in inputs.
roi_count is the number of ROI rectangles.
(Kernel parameter #1)</p>
</li>
<li>
<p><code>[in]</code> <em>pool_type</em> - [static] Of type <code><a href="#vx_nn_pooling_type_e">vx_nn_pooling_type_e</a></code>.
Only <code><a href="#VX_NN_POOLING_MAX">VX_NN_POOLING_MAX</a></code> pooling is supported.
(Kernel parameter #2)</p>
</li>
<li>
<p><code>[in]</code> <em>size_of_roi_params</em> - [static] Size in bytes of roi_pool_params.
Note that this parameter is not counted as one of the kernel parameters.</p>
</li>
<li>
<p><code>[out]</code> <em>output_arr</em> - The output tensor.
Output will have [output_width, output_height, #IFM, roi_count, #batches]
dimensions.
#batches is optional and must be the same as in inputs.
(Kernel parameter #3)</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Returns:</strong> A node reference <code>vx_node</code>.
Any possible errors preventing a successful creation should be checked using
<code>vxGetStatus</code>.</p>
</div>
</div>
<div class="sect4">
<h5 id="_vxsoftmaxlayer">vxSoftmaxLayer</h5>
<div class="paragraph">
<p>[Graph] Creates a Convolutional Network Softmax Layer Node.</p>
</div>
<div id="vxSoftmaxLayer" class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c">vx_node vxSoftmaxLayer(
    vx_graph                                    graph,
    vx_tensor                                   inputs,
    vx_tensor                                   outputs);</code></pre>
</div>
</div>
<div class="paragraph">
<p>The softmax function, is a generalization of the logistic function that
&#8220;squashes&#8221; a K-dimensional vector <span class="eq">z</span> of arbitrary real values to a
K-dimensional vector <span class="eq">σ(z)</span> of real values in the range (0, 1)
that add up to 1.
The function is given by: \(\sigma(z) = \frac{\exp^z}{\sum_i
\exp^{z_i}}\)</p>
</div>
<div class="paragraph">
<p><strong>Parameters</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>[in]</code> <em>graph</em> - The handle to the graph.</p>
</li>
<li>
<p><code>[in]</code> <em>inputs</em> - The input tensor, with the number of dimensions
according to the following scheme.
In case IFM dimension is 1.
Softmax is be calculated on that dimension.
In case IFM dimension is 2.
Softmax is be calculated on the first dimension.
The second dimension is batching.
In case IFM dimension is 3.
Dimensions are [Width, Height, Classes].
And Softmax is calculated on the third dimension.
In case IFM dimension is 4.
Dimensions are [Width, Height, Classes, batching].
Softmax is calculated on the third dimension.
Regarding the layout specification, see <code>vxCreateTensor</code> and
<code>vxCreateVirtualTensor</code>.
In all cases Implementations must support input tensor data types
indicated by the extension strings <code>"KHR_NN_8"</code> or <code>"KHR_NN_8 KHR_NN_16"</code>.</p>
</li>
<li>
<p><code>[out]</code> <em>outputs</em> - The output tensor.
Output will have the same number of dimensions as input.
Output tensor data type must be same as the inputs.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Returns:</strong> A node reference <code>vx_node</code>.
Any possible errors preventing a successful creation should be checked using
<code>vxGetStatus</code>.</p>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div id="footer">
<div id="footer-text">
Version 1.3<br>
Last updated 2019-04-26 07:33:45 UTC
</div>
</div>

<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_HTMLorMML"></script>
</body>
</html>
